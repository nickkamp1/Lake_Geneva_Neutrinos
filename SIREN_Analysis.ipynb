{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb1112-1fe5-4b3b-919c-d6a01fefddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colors import SymLogNorm\n",
    "from scipy.stats import norm,poisson,chi2\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gammaln\n",
    "plt.style.use(\"figures.mplstyle\")\n",
    "\n",
    "light_generators = [\"EPOSLHC\",\"DPMJET\",\"SIBYLL\",\"QGSJET\",\"PYTHIA8\"]\n",
    "charm_generators = [\"BKSS\",\"BKRS\",\"SIBYLL\",\"BDGJKR\",\"MS\"]\n",
    "\n",
    "colors = {(\"EPOSLHC\",\"BKSS\"):\"mediumorchid\",\n",
    "          (\"DPMJET\",\"BKRS\"):\"deepskyblue\",\n",
    "          (\"SIBYLL\",\"SIBYLL\"):\"darkseagreen\",\n",
    "          (\"QGSJET\",\"BDGJKR\"):\"goldenrod\",\n",
    "          (\"PYTHIA8\",\"MS\"):\"indianred\"\n",
    "         }\n",
    "\n",
    "forward_flux_files = {\n",
    "    \"LHC13\":{\n",
    "        \"light\":[\"DPMJET\", \"EPOSLHC\", \"PYTHIA8\", \"QGSJET\", \"SIBYLL\"],\n",
    "        \"charm\":[\"BDGJKR\", \"BKRS\", \"BKSS\", \"MS\", \"SIBYLL\"]\n",
    "    },\n",
    "    \"Large\":{\n",
    "        \"light\":[\"EPOSLHC\"],\n",
    "        \"charm\":[\"BKRS\"]\n",
    "    },\n",
    "    \"Run3\":{\n",
    "        \"light\":[\"EPOSLHC\"],\n",
    "        \"charm\":[\"POWHEG+P8monash\"]\n",
    "    },\n",
    "    \"VLarge\":{\n",
    "        \"light\":[\"EPOSLHC\",\"SIBYLL\"],\n",
    "        \"charm\":[\"BKRS\"]\n",
    "    }\n",
    "}\n",
    "primaries = [12,-12,\n",
    "             14,-14,\n",
    "             16,-16\n",
    "            ]\n",
    "datasets={\"SINE_CMS_West\":[\"CC\"],\n",
    "           \"UNDINE_LHCb_North\":[\"CC\",\"NC\"]}\n",
    "\n",
    "num_UNDINE = 5\n",
    "\n",
    "yearly_factor = 250./3000. # 250 fb^-1 per year / 3 ab^-1 total\n",
    "\n",
    "UNDINE_electron_ebins = np.logspace(1,4,15)\n",
    "UNDINE_muon_ebins = np.logspace(1,4,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbb881-b529-4453-ba0f-027857ff0975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for detector,xs_models in datasets.items():\n",
    "    for xs_model in xs_models:\n",
    "        for prefix,parent_dict in forward_flux_files.items():\n",
    "            if prefix!=\"LHC13\": continue\n",
    "            for parent,generators in parent_dict.items():\n",
    "                for generator in generators:\n",
    "                    for primary in primaries:\n",
    "                        if \"SINE\" in detector and abs(primary)!=14: continue\n",
    "                        if parent==\"light\" and abs(primary)==16: continue\n",
    "                        key = tuple((detector,xs_model,prefix,generator,parent,primary))\n",
    "                        print(key)\n",
    "                        siren_output_file = \"Data/SIREN/Output/%s/%s_%s_%s_%s_%s\"%(detector,prefix,generator,parent,primary,xs_model)\n",
    "                        compressed_output_file = \"Data/SIREN/Output/%s/compressed/%s_%s_%s_%s_%s\"%(detector,prefix,generator,parent,primary,xs_model)\n",
    "                        data[key] = ak.from_parquet(compressed_output_file+\".parquet\")\n",
    "                        # tmp_data = ak.from_parquet(siren_output_file+\".parquet\")\n",
    "                        # if \"SINE\" in detector: \n",
    "                        #     tmp_data = tmp_data[tmp_data.hit_mask_muon_survival]\n",
    "                        # elif \"UNDINE\" in detector: \n",
    "                        #     tmp_data = tmp_data[np.array(tmp_data.in_fiducial)[:,-1]]\n",
    "                        # ak.to_parquet(tmp_data,compressed_output_file+\".parquet\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa0dc6-ce5e-4de8-99fe-108e6889f042",
   "metadata": {},
   "source": [
    "# paper figures from SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba46f0-47d2-4e63-ac58-cc210fb4e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantile(values, quantiles, sample_weight=None, \n",
    "                      values_sorted=False, old_style=False):\n",
    "    \"\"\" Very close to numpy.percentile, but supports weights.\n",
    "    NOTE: quantiles should be in [0, 1]!\n",
    "    :param values: numpy.array with data\n",
    "    :param quantiles: array-like with many quantiles needed\n",
    "    :param sample_weight: array-like of the same length as `array`\n",
    "    :param values_sorted: bool, if True, then will avoid sorting of\n",
    "        initial array\n",
    "    :param old_style: if True, will correct output to be consistent\n",
    "        with numpy.percentile.\n",
    "    :return: numpy.array with computed quantiles.\n",
    "    \"\"\"\n",
    "    values = np.array(values)\n",
    "    quantiles = np.array(quantiles)\n",
    "    if sample_weight is None:\n",
    "        sample_weight = np.ones(len(values))\n",
    "    sample_weight = np.array(sample_weight)\n",
    "    assert np.all(quantiles >= 0) and np.all(quantiles <= 1), \\\n",
    "        'quantiles should be in [0, 1]'\n",
    "\n",
    "    if not values_sorted:\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        sample_weight = sample_weight[sorter]\n",
    "\n",
    "    weighted_quantiles = np.cumsum(sample_weight) - 0.5 * sample_weight\n",
    "    if old_style:\n",
    "        # To be convenient with numpy.percentile\n",
    "        weighted_quantiles -= weighted_quantiles[0]\n",
    "        weighted_quantiles /= weighted_quantiles[-1]\n",
    "    else:\n",
    "        weighted_quantiles /= np.sum(sample_weight)\n",
    "    return np.interp(quantiles, weighted_quantiles, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfc38d-5b49-4fca-a4d6-99c61b36ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"LHC13\"\n",
    "light_generators = [\"EPOSLHC\",\"DPMJET\",\"SIBYLL\",\"QGSJET\",\"PYTHIA8\"]\n",
    "charm_generators = [\"BKSS\",\"BKRS\",\"SIBYLL\",\"BDGJKR\",\"MS\"]\n",
    "\n",
    "kaons = [\n",
    "    130, # K0L\n",
    "    310, # K0S\n",
    "    321, # K+/-\n",
    "    3312, # Theta+/-\n",
    "    3122, # Lambda\n",
    "    3112, # Sigma-\n",
    "    3222, # Sigma+\n",
    "    3322, # Theta0\n",
    "    ]\n",
    "\n",
    "pions = [\n",
    "    211, # pi+/-\n",
    "]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(3,3,figsize=(12,12))\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "twin_ax = np.empty_like(ax)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        twin_ax[i,j] = ax[i,j].twinx()\n",
    "        \n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "ax[0,0].axis(\"off\")\n",
    "ax[0,2].axis(\"off\")\n",
    "twin_ax[0,0].axis(\"off\")\n",
    "twin_ax[0,2].axis(\"off\")\n",
    "\n",
    "Ebins = np.logspace(1,4,30)\n",
    "pids = [12,14,16]\n",
    "\n",
    "\n",
    "\n",
    "total_rates = {}\n",
    "generator_rates = {}\n",
    "generator_pion_rates = {}\n",
    "generator_kaon_rates = {}\n",
    "generator_UNDINE_electron_edist= {}\n",
    "generator_UNDINE_muon_edist = {}\n",
    "generator_UNDINE_electron_pion_edist = {}\n",
    "generator_UNDINE_muon_pion_edist = {}\n",
    "generator_UNDINE_electron_kaon_edist = {}\n",
    "generator_UNDINE_muon_kaon_edist = {}\n",
    "\n",
    "SINE_numu_Erange = []\n",
    "UNDINE_numu_Erange = []\n",
    "UNDINE_nue_Erange = []\n",
    "\n",
    "i = -1\n",
    "for det,xs_models in datasets.items():\n",
    "    \n",
    "    for xs_model in xs_models:\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        Ehist_l_avg = {pid:np.zeros(len(Ebins)-1) for pid in pids}\n",
    "        Ehist_c_avg = {pid:np.zeros(len(Ebins)-1) for pid in pids}\n",
    "        Ehist_avg = {pid:np.zeros(len(Ebins)-1) for pid in pids}\n",
    "\n",
    "        for lg,cg in zip(light_generators,charm_generators):\n",
    "\n",
    "            c = colors[(lg,cg)]\n",
    "            print(lg,cg)\n",
    "\n",
    "            lkey = tuple((det,xs_model,prefix,lg,\"light\"))\n",
    "            ckey = tuple((det,xs_model,prefix,cg,\"charm\"))\n",
    "\n",
    "\n",
    "\n",
    "            for iax,pid in enumerate(pids):\n",
    "\n",
    "\n",
    "\n",
    "                if pid!=16 and not (pid!=14 and \"SINE\" in det):\n",
    "                    ldata = ak.concatenate([data[lkey+(pid,)],data[lkey+(-pid,)]])\n",
    "                    lweights = np.array(ldata.weights)\n",
    "                    if \"SINE\" in det: lweights *= np.array(ldata.hit_mask_muon_survival)\n",
    "                    if \"UNDINE\" in det: lweights *= num_UNDINE*np.array(ldata.in_fiducial)[:,-1]\n",
    "                    #vx = np.squeeze(ldata.vertex)\n",
    "                    Ehist_l,_ = np.histogram(ldata.energy,bins=Ebins,weights=lweights)\n",
    "                    generator_rates[lkey+(pid,)] = sum(lweights)\n",
    "                    generator_UNDINE_electron_edist[lkey+(pid,)],_ = np.histogram(ldata.energy,bins=UNDINE_electron_ebins,weights=lweights)\n",
    "                    generator_UNDINE_muon_edist[lkey+(pid,)],_ = np.histogram(ldata.energy,bins=UNDINE_muon_ebins,weights=lweights)\n",
    "                    pion_indices = np.isin(np.abs(np.array(ldata.hPDG,dtype=int)),pions)\n",
    "                    kaon_indices = np.isin(np.abs(np.array(ldata.hPDG,dtype=int)),kaons)\n",
    "                    pion_weights = lweights[pion_indices]\n",
    "                    kaon_weights = lweights[kaon_indices]\n",
    "                    generator_pion_rates[lkey+(pid,)] = sum(pion_weights)\n",
    "                    generator_kaon_rates[lkey+(pid,)] = sum(kaon_weights)\n",
    "                    generator_UNDINE_electron_pion_edist[lkey+(pid,)],_ = np.histogram(ldata.energy[pion_indices],bins=UNDINE_electron_ebins,weights=pion_weights)\n",
    "                    generator_UNDINE_muon_pion_edist[lkey+(pid,)],_ = np.histogram(ldata.energy[pion_indices],bins=UNDINE_muon_ebins,weights=pion_weights)\n",
    "                    generator_UNDINE_electron_kaon_edist[lkey+(pid,)],_ = np.histogram(ldata.energy[kaon_indices],bins=UNDINE_electron_ebins,weights=kaon_weights)\n",
    "                    generator_UNDINE_muon_kaon_edist[lkey+(pid,)],_ = np.histogram(ldata.energy[kaon_indices],bins=UNDINE_muon_ebins,weights=kaon_weights)\n",
    "                else:\n",
    "                    Ehist_l = np.zeros(len(Ebins)-1)\n",
    "                    generator_rates[lkey+(pid,)] = 0\n",
    "                    generator_pion_rates[lkey+(pid,)] = 0\n",
    "                    generator_kaon_rates[lkey+(pid,)] = 0\n",
    "                    generator_UNDINE_electron_edist[lkey+(pid,)] = np.zeros(len(UNDINE_electron_ebins)-1)\n",
    "                    generator_UNDINE_muon_edist[lkey+(pid,)] = np.zeros(len(UNDINE_muon_ebins)-1)\n",
    "                    generator_UNDINE_electron_pion_edist[lkey+(pid,)] = np.zeros(len(UNDINE_electron_ebins)-1)\n",
    "                    generator_UNDINE_muon_pion_edist[lkey+(pid,)] = np.zeros(len(UNDINE_muon_ebins)-1)\n",
    "                    generator_UNDINE_electron_kaon_edist[lkey+(pid,)] = np.zeros(len(UNDINE_electron_ebins)-1)\n",
    "                    generator_UNDINE_muon_kaon_edist[lkey+(pid,)] = np.zeros(len(UNDINE_muon_ebins)-1)\n",
    "                if not (pid!=14 and \"SINE\" in det):\n",
    "                    cdata = ak.concatenate([data[ckey+(pid,)],data[ckey+(-pid,)]])\n",
    "                    cweights = np.array(cdata.weights)\n",
    "                    if \"SINE\" in det: cweights *= np.array(cdata.hit_mask_muon_survival)\n",
    "                    if \"UNDINE\" in det: cweights *= num_UNDINE*np.array(cdata.in_fiducial)[:,-1]\n",
    "                    #vx = np.squeeze(cdata.vertex)\n",
    "                    Ehist_c,_ = np.histogram(cdata.energy,bins=Ebins,weights=cweights)\n",
    "                    generator_rates[ckey+(pid,)] = sum(cweights)\n",
    "                    generator_UNDINE_electron_edist[ckey+(pid,)],_ = np.histogram(cdata.energy,bins=UNDINE_electron_ebins,weights=cweights)\n",
    "                    generator_UNDINE_muon_edist[ckey+(pid,)],_ = np.histogram(cdata.energy,bins=UNDINE_muon_ebins,weights=cweights)\n",
    "                    pion_indices = np.isin(np.abs(np.array(cdata.hPDG,dtype=int)),pions)\n",
    "                    kaon_indices = np.isin(np.abs(np.array(cdata.hPDG,dtype=int)),kaons)\n",
    "                    pion_weights = cweights[pion_indices]\n",
    "                    kaon_weights = cweights[kaon_indices]\n",
    "                    generator_pion_rates[ckey+(pid,)] = sum(pion_weights)\n",
    "                    generator_kaon_rates[ckey+(pid,)] = sum(kaon_weights)\n",
    "                    generator_UNDINE_electron_pion_edist[ckey+(pid,)],_ = np.histogram(cdata.energy[pion_indices],bins=UNDINE_electron_ebins,weights=pion_weights)\n",
    "                    generator_UNDINE_muon_pion_edist[ckey+(pid,)],_ = np.histogram(cdata.energy[pion_indices],bins=UNDINE_muon_ebins,weights=pion_weights)\n",
    "                    generator_UNDINE_electron_kaon_edist[ckey+(pid,)],_ = np.histogram(cdata.energy[kaon_indices],bins=UNDINE_electron_ebins,weights=kaon_weights)\n",
    "                    generator_UNDINE_muon_kaon_edist[ckey+(pid,)],_ = np.histogram(cdata.energy[kaon_indices],bins=UNDINE_muon_ebins,weights=kaon_weights)\n",
    "                else:\n",
    "                    Ehist_c = np.zeros(len(Ebins)-1)\n",
    "                    generator_rates[ckey+(pid,)] = 0\n",
    "                    generator_pion_rates[ckey+(pid,)] = 0\n",
    "                    generator_kaon_rates[ckey+(pid,)] = 0\n",
    "                    generator_UNDINE_electron_edist[ckey+(pid,)] = np.zeros(len(UNDINE_electron_ebins)-1)\n",
    "                    generator_UNDINE_muon_edist[ckey+(pid,)] = np.zeros(len(UNDINE_muon_ebins)-1)\n",
    "                    generator_UNDINE_electron_pion_edist[ckey+(pid,)] = np.zeros(len(UNDINE_electron_ebins)-1)\n",
    "                    generator_UNDINE_muon_pion_edist[ckey+(pid,)] = np.zeros(len(UNDINE_muon_ebins)-1)\n",
    "                    generator_UNDINE_electron_kaon_edist[ckey+(pid,)] = np.zeros(len(UNDINE_electron_ebins)-1)\n",
    "                    generator_UNDINE_muon_kaon_edist[ckey+(pid,)] = np.zeros(len(UNDINE_muon_ebins)-1)\n",
    "\n",
    "\n",
    "                if cg==\"BKRS\" and xs_model==\"CC\":\n",
    "                    q1 = 0.5 - 2*(1-norm.cdf(1))\n",
    "                    q2 = 0.5 + 2*(1-norm.cdf(1))\n",
    "                    if \"SINE\" in det and pid==14:\n",
    "                        SINE_numu_Erange = weighted_quantile(list(ldata.energy)+list(cdata.energy),[q1,q2],sample_weight=list(lweights)+list(cweights))\n",
    "                    if \"UNDINE\" in det and pid==12:\n",
    "                        UNDINE_nue_Erange = weighted_quantile(list(ldata.energy)+list(cdata.energy),[q1,q2],sample_weight=list(lweights)+list(cweights))\n",
    "                    if \"UNDINE\" in det and pid==14:\n",
    "                        UNDINE_numu_Erange = weighted_quantile(list(ldata.energy)+list(cdata.energy),[q1,q2],sample_weight=list(lweights)+list(cweights))\n",
    "                    \n",
    "                            \n",
    "                \n",
    "                Ehist = np.array(Ehist_l+Ehist_c)\n",
    "                Ehist_avg[pid] += Ehist/len(light_generators)\n",
    "                Ehist_l_avg[pid] += np.array(Ehist_l)/len(light_generators)\n",
    "                Ehist_c_avg[pid] += np.array(Ehist_c)/len(charm_generators)\n",
    "                if i==0 and iax==0:\n",
    "                    ax[i,iax].step([],[],color=c,label=\"%s+%s\"%(lg,cg))\n",
    "                elif i!=0 or iax !=2:\n",
    "                    ax[i,iax].step(Ebins,np.append([0],Ehist),color=c,lw=2)\n",
    "                    ax[i,iax].step(Ebins,np.append([0],Ehist_c),color=c,ls=\"--\",lw=2)\n",
    "\n",
    "        for iax,pid in enumerate(pids):\n",
    "            total_rates[tuple((det,xs_model,\"light\",pid))] = sum(Ehist_l_avg[pid])\n",
    "            total_rates[tuple((det,xs_model,\"charm\",pid))] = sum(Ehist_c_avg[pid])    \n",
    "            if not(i==0 and iax!=1):\n",
    "                ax[i,iax].step(Ebins,np.append([0],Ehist_c_avg[pid]),color=\"black\",ls=\"--\")\n",
    "                ax[i,iax].step(Ebins,np.append([0],Ehist_avg[pid]),color=\"black\")\n",
    "            elif i==0 and iax==0:\n",
    "                 ax[i,iax].plot([],[],label=\"Average\",color=\"black\")\n",
    "            \n",
    "ax[2,1].set_xlabel(\"Neutrino Energy [GeV]\",fontsize=20)\n",
    "ax[1,0].set_ylabel(r\"Interactions in $3000~{\\rm fb}^{-1}$\",fontsize=20)\n",
    "twin_ax[1,2].set_ylabel(r\"Interactions per year\",fontsize=20)\n",
    "ax[0,2].plot([],[],color=\"black\",label=r\"Total ($\\pi$,K,D,$\\Lambda_c$)\")\n",
    "#ax[0,2].plot([],[],color=\"black\",ls='--',label=r\"$\\pi$,K\")\n",
    "ax[0,2].plot([],[],color=\"black\",ls='--',label=r\"Charm Only (D,$\\Lambda_c$)\")\n",
    "ax[0,0].legend(loc=\"center left\",fontsize=14)\n",
    "ax[0,2].legend(loc=\"center right\",fontsize=14)\n",
    "\n",
    "det_labels = [\"SINE CC\",\"UNDINE CC\", \"UNDINE NC\"]\n",
    "particle_labels = [r\"$\\nu_e+\\bar{\\nu}_e$\",\n",
    "                   r\"$\\nu_\\mu+\\bar{\\nu}_\\mu$\",\n",
    "                   r\"$\\nu_\\tau+\\bar{\\nu}_\\tau$\"]\n",
    "for i in [0,1,2]:\n",
    "    for j in [0,1,2]:\n",
    "            \n",
    "        ax[i,j].set_xlim(1e1,Ebins[-1])\n",
    "        ax[i,j].set_ylim(1e0,1e8)\n",
    "        ax[i,j].set_xlim(1e1,1e4)\n",
    "        ax[i,j].tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax[i,j].tick_params(axis='both', which='minor', labelsize=0)\n",
    "        twin_ax[i,j].tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax[i,j].get_xaxis().grid(True,which='major')\n",
    "        ax[i,j].get_yaxis().grid(True,which='both')\n",
    "        \n",
    "        if not(i==0 and j in [0,2]):\n",
    "            ax[i,j].text(11,2e7,det_labels[i][:-2],fontsize=14)\n",
    "            ax[i,j].text(10.5,2e6,det_labels[i][-2:]+\" \"+ particle_labels[j],fontsize=14)\n",
    "            ax[i,j].loglog()\n",
    "            mn, mx = ax[i,j].get_ylim()\n",
    "            twin_ax[i,j].set_ylim(mn*yearly_factor, mx*yearly_factor)\n",
    "            twin_ax[i,j].loglog()\n",
    "        \n",
    "        # xticks\n",
    "        if i!=2: \n",
    "            ax[i,j].set_xticklabels([])\n",
    "        if i!= 0: \n",
    "            ax[i,j].set_xticks(np.logspace(1,3,3))\n",
    "        \n",
    "        # yticks\n",
    "        if i==0 and j==1:\n",
    "            ax[i,j].set_yticks(np.logspace(2,8,4))\n",
    "            ax[i,j].set_yticks(np.logspace(1,8,8),minor=True)\n",
    "        elif i==1 and j==0:\n",
    "            ax[i,j].set_yticks(np.logspace(0,8,5))\n",
    "            ax[i,j].set_yticks(np.logspace(0,8,9),minor=True)\n",
    "        elif i==2 and j==0:\n",
    "            ax[i,j].set_yticks(np.logspace(0,6,4))\n",
    "            ax[i,j].set_yticks(np.logspace(0,7,8),minor=True)\n",
    "        else:\n",
    "            ax[i,j].set_yticks(np.logspace(0,8,9),minor=True)\n",
    "            ax[i,j].set_yticklabels([])\n",
    "        \n",
    "        if (i==0 and j==1) or (j==2 and i in [1,2]):\n",
    "            twin_ax[i,j].set_yticks(np.logspace(0,6,4))\n",
    "        else:\n",
    "            twin_ax[i,j].set_yticklabels([])\n",
    "\n",
    "plt.savefig(\"Figures/SIREN/Distributions.pdf\",dpi=100)\n",
    "plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd8410-1831-4811-907b-cd7d57ba6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "for detector,xs_models in datasets.items():\n",
    "    for xs_model in xs_models:\n",
    "        if xs_model==\"NC\":\n",
    "            rate_light = 0\n",
    "            rate_charm = 0\n",
    "            for pid in pids:\n",
    "                rate_light += total_rates[tuple((detector,xs_model,\"light\",pid))]\n",
    "                rate_charm += total_rates[tuple((detector,xs_model,\"charm\",pid))]\n",
    "            print(\"%s (%s %s) & %s & %s & %s \\\\\\\\\"%(\"SINE\" if \"SINE\" in detector else \"UNDINE\",\n",
    "                                               xs_model,\"$\\\\nu_\\\\alpha + \\\\bar{\\\\nu}_\\\\alpha$\",\n",
    "                                               \"$10^{%1.2f}$\"%np.log10(rate_light+rate_charm),\n",
    "                                               \"$10^{%1.2f}$\"%np.log10(rate_light) if rate_light > 0 else \"0\",\n",
    "                                               \"$10^{%1.2f}$\"%np.log10(rate_charm)))\n",
    "        else:\n",
    "            for pid,pid_label in zip(pids,particle_labels):\n",
    "                if pid!=14 and \"SINE\" in detector: continue\n",
    "                rate_light = total_rates[tuple((detector,xs_model,\"light\",pid))]\n",
    "                rate_charm = total_rates[tuple((detector,xs_model,\"charm\",pid))]\n",
    "\n",
    "                print(\"%s (%s %s) & %s & %s & %s \\\\\\\\\"%(\"SINE\" if \"SINE\" in detector else \"UNDINE\",\n",
    "                       xs_model,pid_label,\n",
    "                       \"$10^{%1.2f}$\"%np.log10(rate_light+rate_charm),\n",
    "                       \"$10^{%1.2f}$\"%np.log10(rate_light) if rate_light > 0 else \"0\",\n",
    "                       \"$10^{%1.2f}$\"%np.log10(rate_charm)))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460390c5-8880-4f99-b442-a6ad310fe096",
   "metadata": {},
   "source": [
    "# Charm production model sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7f43b-6923-4bad-9fd6-9c42f12d80f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exposure_factor = yearly_factor # roughly one month\n",
    "r1_unc = {}\n",
    "r2_unc = {}\n",
    "fig,ax = plt.subplots(2,2,figsize=(16,16))\n",
    "pseudoexp_dir = \"/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/nkamp/Geneva/Lake_Geneva_Neutrinos/Data/SIREN/Output/Pseudoexperiments\"\n",
    "for lg,cg in zip(light_generators,charm_generators):\n",
    "    c = colors[(lg,cg)]\n",
    "    SINE_Total = np.load(\"%s/SINE_Total_All_%s_%s.npy\"%(pseudoexp_dir,lg,cg))\n",
    "    UNDINE_Total = num_UNDINE*np.load(\"%s/UNDINE_Total_All_%s_%s.npy\"%(pseudoexp_dir,lg,cg))\n",
    "    UNDINE_muons = num_UNDINE*np.load(\"%s/UNDINE_muons_All_%s_%s.npy\"%(pseudoexp_dir,lg,cg))\n",
    "    UNDINE_electrons = num_UNDINE*np.load(\"%s/UNDINE_electrons_All_%s_%s.npy\"%(pseudoexp_dir,lg,cg))\n",
    "    SINE_Total_realizations = np.random.poisson(lam=exposure_factor*SINE_Total)\n",
    "    UNDINE_Total_realizations = np.random.poisson(lam=exposure_factor*UNDINE_Total)\n",
    "    UNDINE_muons_realizations = np.random.poisson(lam=exposure_factor*UNDINE_muons)\n",
    "    UNDINE_electrons_realizations = np.random.poisson(lam=exposure_factor*UNDINE_electrons)\n",
    "    #print(SINE_Total,SINE_Total_realizations)\n",
    "    ax[0,0].hist(SINE_Total_realizations,bins=np.linspace(exposure_factor*8e6,exposure_factor*2e7,100),color=c,histtype=\"step\",label=\"%s + %s\"%(lg,cg))\n",
    "    ax[0,1].hist(UNDINE_Total_realizations,bins=np.linspace(exposure_factor*1.2e6,exposure_factor*3e6,100),color=c,histtype=\"step\",label=\"%s + %s\"%(lg,cg))\n",
    "    ax[1,0].hist(UNDINE_muons_realizations,bins=np.linspace(exposure_factor*1e6,exposure_factor*1.7e6,100),color=c,histtype=\"step\",label=\"%s + %s\"%(lg,cg))\n",
    "    ax[1,1].hist(UNDINE_electrons_realizations,bins=np.linspace(exposure_factor*1e5,exposure_factor*1e6,100),color=c,histtype=\"step\",label=\"%s + %s\"%(lg,cg))\n",
    "    r1 = np.sort(SINE_Total/UNDINE_Total,)\n",
    "    r2 = np.sort(UNDINE_muons/UNDINE_electrons)\n",
    "    r1_unc[(lg,cg)] = {}\n",
    "    r2_unc[(lg,cg)] = {}\n",
    "    for sigma in [1,2,3]:\n",
    "        low_cl = (2*(1-norm.cdf(sigma)))\n",
    "        high_cl = 1 - low_cl\n",
    "        for r,r_unc in zip([r1,r2],[r1_unc[(lg,cg)],r2_unc[(lg,cg)]]):\n",
    "            r_down = np.median(r) - r[int(low_cl*len(r))]\n",
    "            r_up = r[int(high_cl*len(r))] - np.median(r)\n",
    "            r_unc[sigma] = (r_down,r_up)\n",
    "#plt.xlim(exposure_factor*6e6,exposure_factor*2.5e7)\n",
    "#plt.ylim(1,1e3)\n",
    "ax[0,0].legend(title=\"%2.1f fb$^{-1}$ (%2.1f day(s))\"%(3000*exposure_factor,exposure_factor/yearly_factor*365))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i,j].semilogy()\n",
    "        ax[i,j].set_ylabel(\"Number of Realizations\")\n",
    "        ax[i,j].set_ylim(1,3e3)\n",
    "ax[0,0].set_xlabel(r\"SINE Event Rate\")\n",
    "ax[0,1].set_xlabel(r\"UNDINE Event Rate\")\n",
    "ax[1,0].set_xlabel(r\"UNDINE Muon Rate\")\n",
    "ax[1,1].set_xlabel(r\"UNDINE Electron Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd462c-f99c-4ac3-b99a-27963af8ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_muon_BR = 0#0.1739\n",
    "norm_error = 0.03\n",
    "exposure_factor = yearly_factor # roughly one month\n",
    "nsigma = 3\n",
    "\n",
    "SINE_rate_nominal = {}\n",
    "UNDINE_rate_nominal = {}\n",
    "UNDINE_muons_nominal = {}\n",
    "UNDINE_electrons_nominal = {}\n",
    "UNDINE_muons_edist_nominal = {}\n",
    "UNDINE_electrons_edist_nominal = {}\n",
    "for lg,cg in zip(light_generators,charm_generators):\n",
    "\n",
    "    c = colors[(lg,cg)]\n",
    "    print(lg,cg)\n",
    "    \n",
    "    SINE_rate_nominal[(lg,cg)] = {}\n",
    "    UNDINE_rate_nominal[(lg,cg)] = {}\n",
    "    UNDINE_muons_nominal[(lg,cg)] = {}\n",
    "    UNDINE_electrons_nominal[(lg,cg)] = {}\n",
    "    UNDINE_muons_edist_nominal[(lg,cg)] = {}\n",
    "    UNDINE_electrons_edist_nominal[(lg,cg)] = {}\n",
    "\n",
    "    # SINE overall rate\n",
    "    lkey = tuple((\"SINE_CMS_West\",\"CC\",prefix,lg,\"light\"))\n",
    "    ckey = tuple((\"SINE_CMS_West\",\"CC\",prefix,cg,\"charm\"))\n",
    "    SINE_rate = generator_rates[lkey+(14,)] + generator_rates[ckey+(14,)]\n",
    "    SINE_rate_pions = generator_pion_rates[lkey+(14,)]\n",
    "    SINE_rate_kaons = generator_kaon_rates[lkey+(14,)]\n",
    "    SINE_rate_charm = generator_rates[ckey+(14,)]\n",
    "\n",
    "    # UNDINE overall rate and energy distributions\n",
    "    UNDINE_rate = 0\n",
    "    UNDINE_muons = 0\n",
    "    UNDINE_electrons = 0\n",
    "    UNDINE_edist_muons = 0\n",
    "    UNDINE_edist_electrons = 0\n",
    "    \n",
    "    UNDINE_rate_pions = 0\n",
    "    UNDINE_muons_pions = 0\n",
    "    UNDINE_electrons_pions = 0\n",
    "    UNDINE_edist_muons_pions = 0\n",
    "    UNDINE_edist_electrons_pions = 0\n",
    "    \n",
    "    UNDINE_rate_kaons = 0\n",
    "    UNDINE_muons_kaons = 0\n",
    "    UNDINE_electrons_kaons = 0\n",
    "    UNDINE_edist_muons_kaons = 0\n",
    "    UNDINE_edist_electrons_kaons = 0\n",
    "    \n",
    "    UNDINE_rate_charm = 0\n",
    "    UNDINE_muons_charm = 0\n",
    "    UNDINE_electrons_charm = 0\n",
    "    UNDINE_edist_muons_charm = 0\n",
    "    UNDINE_edist_electrons_charm = 0\n",
    "    \n",
    "    for xs_model in datasets[\"UNDINE_LHCb_North\"]:\n",
    "        lkey = tuple((\"UNDINE_LHCb_North\",xs_model,prefix,lg,\"light\"))\n",
    "        ckey = tuple((\"UNDINE_LHCb_North\",xs_model,prefix,cg,\"charm\"))\n",
    "        for pid in pids:\n",
    "            \n",
    "            #rates\n",
    "            rate = generator_rates[lkey+(pid,)] + generator_rates[ckey+(pid,)]\n",
    "            pion_rate = generator_pion_rates[lkey+(pid,)]\n",
    "            kaon_rate = generator_kaon_rates[lkey+(pid,)]\n",
    "            charm_rate = generator_rates[ckey+(pid,)]\n",
    "            UNDINE_rate += rate\n",
    "            UNDINE_rate_pions += pion_rate\n",
    "            UNDINE_rate_kaons += kaon_rate\n",
    "            UNDINE_rate_charm += charm_rate\n",
    "            \n",
    "            #energy distributions\n",
    "            electron_edist = np.array(generator_UNDINE_electron_edist[lkey+(pid,)] + generator_UNDINE_electron_edist[ckey+(pid,)])\n",
    "            electron_pion_edist = np.array(generator_UNDINE_electron_pion_edist[lkey+(pid,)])\n",
    "            electron_kaon_edist = np.array(generator_UNDINE_electron_kaon_edist[lkey+(pid,)])\n",
    "            electron_charm_edist = np.array(generator_UNDINE_electron_edist[ckey+(pid,)])\n",
    "            muon_edist = np.array(generator_UNDINE_muon_edist[lkey+(pid,)] + generator_UNDINE_muon_edist[ckey+(pid,)])\n",
    "            muon_pion_edist = np.array(generator_UNDINE_muon_pion_edist[lkey+(pid,)])\n",
    "            muon_kaon_edist = np.array(generator_UNDINE_muon_kaon_edist[lkey+(pid,)])\n",
    "            muon_charm_edist = np.array(generator_UNDINE_muon_edist[ckey+(pid,)])\n",
    "            \n",
    "            \n",
    "            \n",
    "            if xs_model==\"CC\" and pid==14:\n",
    "                UNDINE_muons += rate\n",
    "                UNDINE_muons_pions += pion_rate\n",
    "                UNDINE_muons_kaons += kaon_rate\n",
    "                UNDINE_muons_charm += charm_rate\n",
    "                UNDINE_edist_muons += muon_edist\n",
    "                UNDINE_edist_muons_pions += muon_pion_edist\n",
    "                UNDINE_edist_muons_kaons += muon_kaon_edist\n",
    "                UNDINE_edist_muons_charm += muon_charm_edist\n",
    "            if xs_model==\"CC\" and pid==16:\n",
    "                UNDINE_muons += tau_muon_BR*rate\n",
    "                UNDINE_muons_pions += tau_muon_BR*pion_rate\n",
    "                UNDINE_muons_kaons += tau_muon_BR*kaon_rate\n",
    "                UNDINE_muons_charm += tau_muon_BR*charm_rate\n",
    "                UNDINE_edist_muons += tau_muon_BR*muon_edist\n",
    "                UNDINE_edist_muons_pions += tau_muon_BR*muon_pion_edist\n",
    "                UNDINE_edist_muons_kaons += tau_muon_BR*muon_kaon_edist\n",
    "                UNDINE_edist_muons_charm += tau_muon_BR*muon_charm_edist\n",
    "            if xs_model==\"CC\" and pid==12:\n",
    "                UNDINE_electrons += rate\n",
    "                UNDINE_electrons_pions += pion_rate\n",
    "                UNDINE_electrons_kaons += kaon_rate\n",
    "                UNDINE_electrons_charm += charm_rate\n",
    "                UNDINE_edist_electrons += electron_edist\n",
    "                UNDINE_edist_electrons_pions += electron_pion_edist\n",
    "                UNDINE_edist_electrons_kaons += electron_kaon_edist\n",
    "                UNDINE_edist_electrons_charm += electron_charm_edist\n",
    "           \n",
    "    \n",
    "    SINE_rate_nominal[(lg,cg)][\"All\"] = SINE_rate\n",
    "    UNDINE_rate_nominal[(lg,cg)][\"All\"] = UNDINE_rate\n",
    "    UNDINE_muons_nominal[(lg,cg)][\"All\"] = UNDINE_muons\n",
    "    UNDINE_electrons_nominal[(lg,cg)][\"All\"] = UNDINE_electrons\n",
    "    UNDINE_muons_edist_nominal[(lg,cg)][\"All\"] = UNDINE_edist_muons\n",
    "    UNDINE_electrons_edist_nominal[(lg,cg)][\"All\"] = UNDINE_edist_electrons\n",
    "    \n",
    "    SINE_rate_nominal[(lg,cg)][\"Pions\"] = SINE_rate_pions\n",
    "    UNDINE_rate_nominal[(lg,cg)][\"Pions\"] = UNDINE_rate_pions\n",
    "    UNDINE_muons_nominal[(lg,cg)][\"Pions\"] = UNDINE_muons_pions\n",
    "    UNDINE_electrons_nominal[(lg,cg)][\"Pions\"] = UNDINE_electrons_pions\n",
    "    UNDINE_muons_edist_nominal[(lg,cg)][\"Pions\"] = UNDINE_edist_muons_pions\n",
    "    UNDINE_electrons_edist_nominal[(lg,cg)][\"Pions\"] = UNDINE_edist_electrons_pions\n",
    "    \n",
    "    SINE_rate_nominal[(lg,cg)][\"Kaons\"] = SINE_rate_kaons\n",
    "    UNDINE_rate_nominal[(lg,cg)][\"Kaons\"] = UNDINE_rate_kaons\n",
    "    UNDINE_muons_nominal[(lg,cg)][\"Kaons\"] = UNDINE_muons_kaons\n",
    "    UNDINE_electrons_nominal[(lg,cg)][\"Kaons\"] = UNDINE_electrons_kaons\n",
    "    UNDINE_muons_edist_nominal[(lg,cg)][\"Kaons\"] = UNDINE_edist_muons_kaons\n",
    "    UNDINE_electrons_edist_nominal[(lg,cg)][\"Kaons\"] = UNDINE_edist_electrons_kaons\n",
    "    \n",
    "    SINE_rate_nominal[(lg,cg)][\"Charm\"] = SINE_rate_charm\n",
    "    UNDINE_rate_nominal[(lg,cg)][\"Charm\"] = UNDINE_rate_charm\n",
    "    UNDINE_muons_nominal[(lg,cg)][\"Charm\"] = UNDINE_muons_charm\n",
    "    UNDINE_electrons_nominal[(lg,cg)][\"Charm\"] = UNDINE_electrons_charm\n",
    "    UNDINE_muons_edist_nominal[(lg,cg)][\"Charm\"] = UNDINE_edist_muons_charm\n",
    "    UNDINE_electrons_edist_nominal[(lg,cg)][\"Charm\"] = UNDINE_edist_electrons_charm\n",
    "    \n",
    "    SINE_rate *= exposure_factor\n",
    "    UNDINE_rate *= exposure_factor\n",
    "    UNDINE_muons *= exposure_factor\n",
    "    UNDINE_electrons *= exposure_factor\n",
    "    \n",
    "    r1 = SINE_rate / UNDINE_rate\n",
    "    r2 = UNDINE_muons / UNDINE_electrons\n",
    "    #r1_err = r1 * np.sqrt((norm_error*SINE_rate/SINE_rate)**2 + (norm_error*total_lake/total_lake)**2)\n",
    "    #r2_err = r2 * np.sqrt((norm_error*tracks_lake/tracks_lake)**2 + (norm_error*cascades_lake/cascades_lake)**2)\n",
    "    r1_xs_err = list(r1_unc[(lg,cg)][nsigma])\n",
    "    r2_xs_err = list(r2_unc[(lg,cg)][nsigma])\n",
    "    \n",
    "    r1_stat_err = nsigma * r1 * np.sqrt(1/SINE_rate + 1/UNDINE_rate)\n",
    "    r2_stat_err = nsigma * r2 * np.sqrt(1/UNDINE_muons + 1/UNDINE_electrons)\n",
    "    \n",
    "    r1_err_low = np.sqrt(r1_stat_err**2 + r1_xs_err[0]**2)\n",
    "    r1_err_high = np.sqrt(r1_stat_err**2 + r1_xs_err[1]**2)\n",
    "    r2_err_low = np.sqrt(r2_stat_err**2 + r2_xs_err[0]**2)\n",
    "    r2_err_high = np.sqrt(r2_stat_err**2 + r2_xs_err[1]**2)\n",
    "    \n",
    "    plt.errorbar(r1,r2,\n",
    "                 xerr=r1_stat_err,\n",
    "                 yerr=r2_stat_err,\n",
    "                 color=c,lw=3)\n",
    "    plt.errorbar(r1,r2,\n",
    "                 xerr=np.expand_dims((r1_err_low,r1_err_high),-1),\n",
    "                 yerr=np.expand_dims((r2_err_low,r2_err_high),-1),\n",
    "                 color=c,lw=1,capsize=8)\n",
    "    #for cap in caplines: cap.set_marker('v')\n",
    "    plt.plot([],[],color=c,label=\"%s + %s\"%(lg,cg))\n",
    "    \n",
    "    \n",
    "plt.errorbar([-1],[-1],xerr=[2],yerr=[2],color=\"black\",lw=1,capsize=5,label=r\"$%d (\\sigma_{\\rm stat} \\oplus \\sigma_{\\rm xs})$\"%nsigma)\n",
    "plt.errorbar([],[],xerr=[],yerr=[],color=\"black\",lw=3,label=r\"$%d \\sigma_{\\rm stat}$\"%nsigma)\n",
    "plt.legend(title=r\"%d ${\\rm fb}^{-1}$ (%2.1f days)\"%(3000*exposure_factor,exposure_factor/yearly_factor*365),loc=\"lower left\")\n",
    "plt.xlim(6.0,9.5)\n",
    "plt.ylim(2,7)\n",
    "plt.xlabel(\"(SINE Total) / (UNDINE Total)\")\n",
    "plt.ylabel(r\"(UNDINE $\\mu$) / (UNDINE $e$)\")\n",
    "plt.gcf().set_facecolor(\"white\")\n",
    "plt.gcf().patch.set_alpha(0.0)\n",
    "plt.savefig(\"Figures/SIREN/GeneratorDifferntiator.pdf\",dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a896f-bccd-4b3f-85ad-e974afa1a211",
   "metadata": {},
   "source": [
    "# Cross section sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84594538-dd5d-4e16-8cc4-22b3bf14dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import siren\n",
    "\n",
    "numu = (siren.dataclasses.Particle.ParticleType)(14)\n",
    "nue = (siren.dataclasses.Particle.ParticleType)(12)\n",
    "numubar = (siren.dataclasses.Particle.ParticleType)(-14)\n",
    "nuebar = (siren.dataclasses.Particle.ParticleType)(-12)\n",
    "\n",
    "cross_section_model = \"CSMSDISSplines\"\n",
    "\n",
    "#xsfiledir = siren.utilities.get_cross_section_model_path(cross_section_model)\n",
    "xsfiledir = \"/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/nkamp/Geneva/Lake_Geneva_Neutrinos/Data/SIREN/CrossSections/\"\n",
    "unc_data = pd.read_csv(\"%s/xs_wcg24b_isoscalar.txt\"%xsfiledir)\n",
    "\n",
    "# Cross Section Model\n",
    "target_type = siren.dataclasses.Particle.ParticleType.Nucleon\n",
    "\n",
    "DIS_xs = {}\n",
    "DIS_xs_unc = {}\n",
    "DIS_xs_labels = {}\n",
    "\n",
    "for primary,label in zip([12,14,16,-12,-14,-16],\n",
    "                         [\"$\\nu_e$\",\"$\\nu_\\mu$\",\"$\\nu_\\tau$\",\n",
    "                          \"$\\bar{\\nu}_e$\",\"$\\bar{\\nu}_\\mu$\",\"$\\bar{\\nu}_\\tau$\"]):\n",
    "    if primary>0:\n",
    "        nutype = \"neutrino\"\n",
    "        unc_particle = \"NUMU\"\n",
    "    else:\n",
    "        nutype = \"antineutrino\"\n",
    "        unc_particle = \"NUMUBAR\"\n",
    "    if abs(primary) in [12,14]: nuflavor = \"muon\"\n",
    "    else: nuflavor = \"tau\"\n",
    "    \n",
    "    for xs_mode in [\"CC\",\"NC\"]:\n",
    "        \n",
    "        minQ2 = 0.01 if xs_mode==\"CC\" else 1\n",
    "        primary_type = (siren.dataclasses.Particle.ParticleType)(primary)\n",
    "\n",
    "        DIS_xs[(primary,xs_mode)] = siren.interactions.DISFromSpline(\n",
    "                                        os.path.join(xsfiledir, \"wcg24b_dsdxdy_%s_%s_%s_isoscalar.fits\"%(xs_mode,nuflavor,nutype)),\n",
    "                                        os.path.join(xsfiledir, \"wcg24b_sigma_%s_%s_%s_isoscalar.fits\"%(xs_mode,nuflavor,nutype)),\n",
    "                                        1,siren.utilities.Constants.isoscalarMass,minQ2,\n",
    "                                        [primary_type],\n",
    "                                        [target_type], \"cm\"\n",
    "                                    )\n",
    "        DIS_xs_labels[(primary,xs_mode)] = r\"%s %s\"%(label,xs_mode)\n",
    "        DIS_xs_unc[(primary,xs_mode)] = interp1d(unc_data[\"E[GEV]\"],unc_data[\"UNC_%s_%s[%%]\"%(unc_particle,xs_mode)],fill_value=\"extrapolate\")\n",
    "\n",
    "erange = np.logspace(1,4,100)\n",
    "DIS_xs_range = {}\n",
    "for (primary,xs_mode),xs in DIS_xs.items():\n",
    "    primary_type = (siren.dataclasses.Particle.ParticleType)(primary)\n",
    "    DIS_xs_range[(primary,xs_mode)] = [DIS_xs[(primary,xs_mode)].TotalCrossSection(primary_type,e) for e in erange]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f83f7-2449-4487-af49-923942f4e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_factor = yearly_factor#1./150.\n",
    "n_sigma_bottom=1\n",
    "n_sigma_top=5\n",
    "\n",
    "UNDINE_color=\"deepskyblue\"\n",
    "FASER_color=\"orangered\"\n",
    "SINE_color=\"forestgreen\"\n",
    "\n",
    "# flux ratios from arXiv:2403.12520\n",
    "nu_nubar_nue = 1.03\n",
    "nu_nubar_numu = 0.62\n",
    "faser_nue_erange = np.linspace(560,1740,100)\n",
    "faser_nue_alpha = [2.4,1.3,1.8] # cross section scaling\n",
    "faser_nue_xs = [1.2,0.7,0.8]\n",
    "faser_numu_erange = np.linspace(520,1760,100)\n",
    "faser_numu_alpha = [0.9,0.3,0.5] # cross section scaling\n",
    "faser_numu_xs = [0.5,0.2,0.2]\n",
    "faser_numu_avg_xsec = [1./(1+nu_nubar_numu)*(DIS_xs[(14,\"CC\")].TotalCrossSection(numu,e) + nu_nubar_numu*DIS_xs[(-14,\"CC\")].TotalCrossSection(numubar,e)) for e in faser_numu_erange]\n",
    "faser_nue_avg_xsec = [1./(1+nu_nubar_nue)*(DIS_xs[(12,\"CC\")].TotalCrossSection(nue,e) + nu_nubar_nue*DIS_xs[(-12,\"CC\")].TotalCrossSection(nuebar,e)) for e in faser_nue_erange]\n",
    "\n",
    "numu_avg_xsec = [1./(1+nu_nubar_numu)*(DIS_xs[(14,\"CC\")].TotalCrossSection(numu,e) + nu_nubar_numu*DIS_xs[(-14,\"CC\")].TotalCrossSection(numubar,e)) for e in erange]\n",
    "nue_avg_xsec = [1./(1+nu_nubar_nue)*(DIS_xs[(12,\"CC\")].TotalCrossSection(nue,e) + nu_nubar_nue*DIS_xs[(-12,\"CC\")].TotalCrossSection(nuebar,e)) for e in erange]\n",
    "\n",
    "fig,ax = plt.subplots(2,2,figsize=(16,8),sharex=\"col\",sharey=\"row\")\n",
    "fig.subplots_adjust(hspace=0.0,wspace=0.0)\n",
    "\n",
    "SINE_numu_n = exposure_factor*(total_rates[\"SINE_CMS_West\",'CC','light',14] + total_rates[\"SINE_CMS_West\",'CC','charm',14])\n",
    "UNDINE_numu_n = exposure_factor*(total_rates[\"UNDINE_LHCb_North\",'CC','light',14] + total_rates[\"UNDINE_LHCb_North\",'CC','charm',14])\n",
    "UNDINE_nue_n = exposure_factor*(total_rates[\"UNDINE_LHCb_North\",'CC','light',12] + total_rates[\"UNDINE_LHCb_North\",'CC','charm',12])\n",
    "\n",
    "SINE_numu_stat_err = 1./np.sqrt(SINE_numu_n)\n",
    "UNDINE_numu_stat_err = 1./np.sqrt(UNDINE_numu_n)\n",
    "UNDINE_nue_stat_err = 1./np.sqrt(UNDINE_nue_n)\n",
    "\n",
    "\n",
    "ax[0,0].plot(erange,DIS_xs_range[(14,\"CC\")]/erange/1e-38,color=\"black\",ls=\"-\",label=r\"WCG $\\sigma_{\\nu_e}$\")\n",
    "ax[0,0].plot(erange,DIS_xs_range[(-14,\"CC\")]/erange/1e-38,color=\"black\",ls=\"--\",label=r\"WCG $\\sigma_{\\bar{\\nu}_e}$\")\n",
    "ax[0,1].plot(erange,DIS_xs_range[(14,\"CC\")]/erange/1e-38,color=\"black\",ls=\"-\",label=r\"WCG $\\sigma_{\\nu_\\mu}$\")\n",
    "ax[0,1].plot(erange,DIS_xs_range[(-14,\"CC\")]/erange/1e-38,color=\"black\",ls=\"--\",label=r\"WCG $\\sigma_{\\bar{\\nu}_\\mu}$\")\n",
    "ax[0,1].plot(erange,numu_avg_xsec/erange/1e-38,color=\"black\",ls=\":\",label=\"WCG Weighted Average\")\n",
    "ax[0,0].plot(erange,nue_avg_xsec/erange/1e-38,color=\"black\",ls=\":\",label=\"WCG Weighted Average\")\n",
    "\n",
    "FASER_midpoint = int(len(faser_nue_erange)/3)\n",
    "ax[0,0].plot(faser_nue_erange,\n",
    "             #faser_nue_xs[0]*np.ones_like(faser_nue_erange),\n",
    "             faser_nue_alpha[0]*np.array(faser_nue_avg_xsec)/faser_nue_erange/1e-38,\n",
    "             color=FASER_color)\n",
    "ax[0,0].errorbar(faser_nue_erange[FASER_midpoint],faser_nue_alpha[0]*faser_nue_avg_xsec[FASER_midpoint]/faser_nue_erange[FASER_midpoint]/1e-38,\n",
    "                 xerr=0,yerr=[[(faser_nue_alpha[1])*faser_nue_avg_xsec[FASER_midpoint]/faser_nue_erange[FASER_midpoint]/1e-38],\n",
    "                              [(faser_nue_alpha[2])*faser_nue_avg_xsec[FASER_midpoint]/faser_nue_erange[FASER_midpoint]/1e-38]],\n",
    "                 color=FASER_color,capsize=0,label=r\"FASER$\\nu$ $\\sigma_{\\nu_e}$\"+\"\\n\"+r\"$\\pm 1 \\sigma_{\\rm stat+syst}\\,(9.5\\;{\\rm fb}^{-1})$\")\n",
    "ax[0,0].fill_between(faser_nue_erange,\n",
    "                     #(faser_nue_xs[0]-faser_nue_xs[1])*np.ones_like(faser_nue_erange),\n",
    "                     (faser_nue_alpha[0]-faser_nue_alpha[1])*np.array(faser_nue_avg_xsec)/faser_nue_erange/1e-38,\n",
    "                     #(faser_nue_xs[2]+faser_nue_xs[0])*np.ones_like(faser_nue_erange),\n",
    "                     (faser_nue_alpha[0]+faser_nue_alpha[2])*np.array(faser_nue_avg_xsec)/faser_nue_erange/1e-38,\n",
    "                     color=FASER_color,alpha=0.2)\n",
    "ax[0,1].plot(faser_numu_erange,\n",
    "             #faser_numu_xs[0]*np.ones_like(faser_numu_erange),\n",
    "             faser_numu_alpha[0]*np.array(faser_numu_avg_xsec)/faser_numu_erange/1e-38,\n",
    "             color=FASER_color)\n",
    "ax[0,1].errorbar(faser_numu_erange[FASER_midpoint],faser_numu_alpha[0]*faser_numu_avg_xsec[FASER_midpoint]/faser_numu_erange[FASER_midpoint]/1e-38,\n",
    "                 xerr=0,yerr=[[(faser_numu_alpha[1])*faser_numu_avg_xsec[FASER_midpoint]/faser_numu_erange[FASER_midpoint]/1e-38],\n",
    "                              [(faser_numu_alpha[2])*faser_numu_avg_xsec[FASER_midpoint]/faser_numu_erange[FASER_midpoint]/1e-38]],\n",
    "                 color=FASER_color,capsize=0,label=r\"FASER$\\nu$ $\\sigma_{\\nu_\\mu}$\"+\"\\n\"+r\"$\\pm 1 \\sigma_{\\rm stat+syst}\\,(9.5\\;{\\rm fb}^{-1})$\")\n",
    "ax[0,1].fill_between(faser_numu_erange,\n",
    "                     #(faser_numu_xs[0]-faser_nue_xs[1])*np.ones_like(faser_numu_erange),\n",
    "                     (faser_numu_alpha[0]-faser_numu_alpha[1])*np.array(faser_numu_avg_xsec)/faser_numu_erange/1e-38,\n",
    "                     #(faser_nue_xs[2]+faser_nue_xs[0])*np.ones_like(faser_nue_erange),\n",
    "                     (faser_numu_alpha[0]+faser_numu_alpha[2])*np.array(faser_numu_avg_xsec)/faser_numu_erange/1e-38,\n",
    "                     color=FASER_color,alpha=0.2)\n",
    "\n",
    "\n",
    "UNDINE_numu_Erange_arr = np.linspace(*UNDINE_numu_Erange,100)\n",
    "UNDINE_numu_avg_xsec = [1./(1+nu_nubar_numu)*(DIS_xs[(14,\"CC\")].TotalCrossSection(numu,e) + nu_nubar_numu*DIS_xs[(-14,\"CC\")].TotalCrossSection(numubar,e)) for e in UNDINE_numu_Erange_arr]\n",
    "#ax[0].plot(UNDINE_numu_Erange_arr,UNDINE_numu_avg_xsec/UNDINE_numu_Erange_arr/1e-38,color=\"dodgerblue\")\n",
    "ax[0,1].fill_between(UNDINE_numu_Erange_arr,\n",
    "                   (1-n_sigma_top*UNDINE_numu_stat_err)*(UNDINE_numu_avg_xsec/UNDINE_numu_Erange_arr/1e-38),\n",
    "                   (1+n_sigma_top*UNDINE_numu_stat_err)*(UNDINE_numu_avg_xsec/UNDINE_numu_Erange_arr/1e-38),\n",
    "                   color=UNDINE_color,alpha=0.5,\n",
    "                     label=r\"UNDINE $\\sigma_{\\nu_\\mu}$\"+\"\\n\"+r\"$\\pm %d\\sigma_{\\rm stat}\\,(%d\\;{\\rm fb}^{-1})$\"%(n_sigma_top,3000*exposure_factor))\n",
    "\n",
    "UNDINE_nue_Erange_arr = np.linspace(*UNDINE_nue_Erange,100)\n",
    "UNDINE_nue_avg_xsec = [1./(1+nu_nubar_nue)*(DIS_xs[(12,\"CC\")].TotalCrossSection(nue,e) + nu_nubar_nue*DIS_xs[(-12,\"CC\")].TotalCrossSection(nuebar,e)) for e in UNDINE_nue_Erange_arr]\n",
    "#ax[0].plot(UNDINE_nue_Erange_arr,UNDINE_nue_avg_xsec/UNDINE_nue_Erange_arr/1e-38,color=\"dodgerblue\")\n",
    "ax[0,0].fill_between(UNDINE_nue_Erange_arr,\n",
    "                   (1-n_sigma_top*UNDINE_nue_stat_err)*(UNDINE_nue_avg_xsec/UNDINE_nue_Erange_arr/1e-38),\n",
    "                   (1+n_sigma_top*UNDINE_nue_stat_err)*(UNDINE_nue_avg_xsec/UNDINE_nue_Erange_arr/1e-38),\n",
    "                   color=UNDINE_color,alpha=0.5,\n",
    "                     label=r\"UNDINE $\\sigma_{\\nu_e}$\"+\"\\n\"+r\"$\\pm %d\\sigma_{\\rm stat}\\,(%d\\;{\\rm fb}^{-1})$\"%(n_sigma_top,3000*exposure_factor))\n",
    "\n",
    "SINE_numu_Erange_arr = np.linspace(*SINE_numu_Erange,100)\n",
    "SINE_numu_avg_xsec = [1./(1+nu_nubar_numu)*(DIS_xs[(14,\"CC\")].TotalCrossSection(numu,e) + nu_nubar_numu*DIS_xs[(-14,\"CC\")].TotalCrossSection(numubar,e)) for e in SINE_numu_Erange_arr]\n",
    "#ax[0].plot(SINE_numu_Erange_arr,SINE_numu_avg_xsec/SINE_numu_Erange_arr/1e-38,color=\"orangered\")\n",
    "ax[0,1].fill_between(SINE_numu_Erange_arr,\n",
    "                   (1-n_sigma_top*SINE_numu_stat_err)*(SINE_numu_avg_xsec/SINE_numu_Erange_arr/1e-38),\n",
    "                   (1+n_sigma_top*SINE_numu_stat_err)*(SINE_numu_avg_xsec/SINE_numu_Erange_arr/1e-38),\n",
    "                   color=SINE_color,alpha=0.5,\n",
    "                     label=r\"SINE $\\sigma_{\\nu_\\mu}$\"+\"\\n\"+r\"$\\pm %d\\sigma_{\\rm stat}\\,(%d\\;{\\rm fb}^{-1})$\"%(n_sigma_top,3000*exposure_factor))\n",
    "\n",
    "\n",
    "# ratio plot\n",
    "\n",
    "ax[1,0].plot(erange,np.ones_like(erange),alpha=0.3,color=\"black\")\n",
    "ax[1,0].fill_between(erange,\n",
    "                   1-(1./(1+nu_nubar_nue)*(DIS_xs_unc[(12,\"CC\")](erange) + nu_nubar_nue*DIS_xs_unc[(-12,\"CC\")](erange))/100.),\n",
    "                   1+(1./(1+nu_nubar_nue)*(DIS_xs_unc[(12,\"CC\")](erange) + nu_nubar_nue*DIS_xs_unc[(-12,\"CC\")](erange))/100.),\n",
    "                   color=\"black\",alpha=0.2,label=\"WCG $\\pm 1 \\sigma_{pred}$\")\n",
    "\n",
    "ax[1,1].plot(erange,np.ones_like(erange),alpha=0.3,color=\"black\")\n",
    "ax[1,1].fill_between(erange,\n",
    "                   1-(1./(1+nu_nubar_numu)*(DIS_xs_unc[(14,\"CC\")](erange) + nu_nubar_numu*DIS_xs_unc[(-14,\"CC\")](erange))/100.),\n",
    "                   1+(1./(1+nu_nubar_numu)*(DIS_xs_unc[(14,\"CC\")](erange) + nu_nubar_numu*DIS_xs_unc[(-14,\"CC\")](erange))/100.),\n",
    "                   color=\"black\",alpha=0.2,label=\"WCG $\\pm 1 \\sigma_{pred}$\")\n",
    "\n",
    "# ax[1,0].plot(faser_nue_erange,\n",
    "#            faser_nue_alpha[0]*np.ones_like(faser_nue_erange),\n",
    "#            color=FASER_color,label=r\"FASER $\\sigma_{\\nu_e}$\")\n",
    "# ax[1,0].fill_between(faser_nue_erange,\n",
    "#                    (faser_nue_alpha[0]-faser_nue_alpha[1])*np.ones_like(faser_nue_erange),\n",
    "#                    (faser_nue_alpha[0]+faser_nue_alpha[2])*np.ones_like(faser_nue_erange),\n",
    "#                    color=FASER_color,alpha=0.2)\n",
    "# ax[1,1].plot(faser_numu_erange,\n",
    "#            faser_numu_alpha[0]*np.ones_like(faser_numu_erange),\n",
    "#            color=FASER_color,label=r\"FASER $\\sigma_{\\nu_\\mu}$\")\n",
    "# ax[1,1].fill_between(faser_numu_erange,\n",
    "#                    (faser_numu_alpha[0]-faser_numu_alpha[1])*np.ones_like(faser_numu_erange),\n",
    "#                    (faser_numu_alpha[0]+faser_numu_alpha[2])*np.ones_like(faser_numu_erange),\n",
    "#                    color=FASER_color,alpha=0.2)\n",
    "\n",
    "\n",
    "ax[1,1].fill_between(UNDINE_numu_Erange_arr,\n",
    "                   (1-n_sigma_bottom*UNDINE_numu_stat_err),\n",
    "                   (1+n_sigma_bottom*UNDINE_numu_stat_err),\n",
    "                   color=UNDINE_color,alpha=0.5,\n",
    "                    label=r\"UNDINE $\\sigma_{\\nu_\\mu}$\"+\"\\n\"+r\"$\\pm %d\\sigma_{\\rm stat}\\,(%d\\;{\\rm fb}^{-1})$\"%(n_sigma_bottom,3000*exposure_factor))\n",
    "ax[1,0].fill_between(UNDINE_nue_Erange_arr,\n",
    "                   (1-n_sigma_bottom*UNDINE_nue_stat_err),\n",
    "                   (1+n_sigma_bottom*UNDINE_nue_stat_err),\n",
    "                   color=UNDINE_color,alpha=0.5,\n",
    "                     label=r\"UNDINE $\\sigma_{\\nu_e}$\"+\"\\n\"+r\"$\\pm %d\\sigma_{\\rm stat}\\,(%d\\;{\\rm fb}^{-1})$\"%(n_sigma_bottom,3000*exposure_factor))\n",
    "ax[1,1].fill_between(SINE_numu_Erange_arr,\n",
    "                   (1-n_sigma_bottom*SINE_numu_stat_err),\n",
    "                   (1+n_sigma_bottom*SINE_numu_stat_err),\n",
    "                   color=SINE_color,alpha=0.5,\n",
    "                     label=r\"SINE $\\sigma_{\\nu_\\mu}$\"+\"\\n\"+r\"$\\pm %d\\sigma_{\\rm stat}\\,(%d\\;{\\rm fb}^{-1})$\"%(n_sigma_bottom,3000*exposure_factor))\n",
    "\n",
    "emin=1.8e2\n",
    "sigmax=7\n",
    "ax[0,0].text(1.1*emin,0.7*sigmax,r\"$\\nu_e$\",fontsize=25)\n",
    "ax[1,0].text(1.1*emin,1.03,r\"$\\nu_e$\",fontsize=25)\n",
    "ax[0,0].text(1.1*emin,0.7,r\"$\\nu$\",fontsize=18)\n",
    "ax[0,0].text(1.1*emin,0.25,r\"$\\bar{\\nu}$\",fontsize=18)\n",
    "ax[0,1].text(1.1*emin,0.7*sigmax,r\"$\\nu_\\mu$\",fontsize=25)\n",
    "ax[1,1].text(1.1*emin,1.03,r\"$\\nu_\\mu$\",fontsize=25)\n",
    "ax[0,1].text(1.1*emin,0.7,r\"$\\nu$\",fontsize=18)\n",
    "ax[0,1].text(1.1*emin,0.25,r\"$\\bar{\\nu}$\",fontsize=18)\n",
    "\n",
    "ax[0,0].legend(fontsize=13)\n",
    "ax[0,1].legend(fontsize=13,ncol=2)\n",
    "ax[1,0].legend(fontsize=13)\n",
    "ax[1,1].legend(fontsize=13,ncol=3,loc=\"lower left\")\n",
    "\n",
    "\n",
    "\n",
    "ax[0,0].loglog()\n",
    "ax[0,1].loglog()\n",
    "ax[0,0].set_ylim(2e-1,sigmax)\n",
    "ax[0,0].set_ylabel(r\"$\\frac{\\sigma(E_\\nu)}{E_\\nu}\\,(10^{-38}\\,{\\rm cm}^2\\,{\\rm GeV}^{-1})$ \")\n",
    "ax[1,0].semilogx()\n",
    "ax[1,1].semilogx()\n",
    "ax[1,0].set_ylim(0.96,1.04)\n",
    "ax[1,0].set_xlim(emin,erange[-1])\n",
    "ax[1,1].set_xlim(emin,erange[-1])\n",
    "ax[1,0].set_ylabel(r\"$\\sigma(E_\\nu)^{\\rm obs}/\\sigma(E_\\nu)^{\\rm pred}$ \")\n",
    "ax[1,0].set_xlabel(r\"Neutrino Energy $E_\\nu$ (GeV)\")\n",
    "ax[1,1].set_xlabel(r\"Neutrino Energy $E_\\nu$ (GeV)\")\n",
    "# ax[1,0].set_xticklabels(ax[1,0].get_xticklabels()[:-2])\n",
    "# ax[1,0].set_yticks(ax[1,0].get_yticks()[:-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Figures/SIREN/CrossSection.pdf\",dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037ff40-a88a-4a1c-aad7-9d2f975cf7b8",
   "metadata": {},
   "source": [
    "# Strangeness Enhancement Sensitivity\n",
    "Following https://arxiv.org/abs/2309.10417"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a336e7-2c9c-44b2-a93c-0ec2c30484dd",
   "metadata": {},
   "source": [
    "We want to compute the Fisher matrix of the log likelihood ratio test statistic in order to estimate the uncertainty from different hadron interaction models.\n",
    "\n",
    "The likelihood here is given by\n",
    "\n",
    "$$\\mathcal{L}(\\{k_d\\}|\\{\\mu_d\\}) = \\prod_{d \\in \\{{\\rm S_{tot},U_{tot},U_{\\mu},U_e}\\}} \\frac{\\mu_d^{k_d} e^{-\\mu_d}}{k_d!}$$.\n",
    "\n",
    "The prediction is given by \n",
    "\n",
    "$$\n",
    "\\mu_d = \\sum_{p \\in \\{\\pi,K,c\\}} \\frac{1}{N_p} \n",
    "\\big[ \n",
    "G_0^{p,d} \\big(1 - \\sum_{i=1}^{N_p - 1} \\lambda_i^p \\big) \n",
    "+ \\sum_{i=1}^{N_p-1} G_i^{p,d} \\big( 1 + N_p \\lambda_i^p - \\sum_{j=1}^{N_p-1} \\lambda_j^p \\big)\n",
    "\\big],\n",
    "$$\n",
    "\n",
    "where $G_i^{p,d}$ is the prediction from parent meson $p$ in dataset $d$ for generator $i = \\{{\\rm EPOSLHC,SIBYLL,...}\\}$, for example. The $\\lambda_i^p$ are parameters that control the deviation from the nominal prediction. The test statistic that we use to compute the Fisher matrix is\n",
    "\n",
    "$$r \\equiv \\frac{\\mathcal{L}(\\{k_d\\}|\\{\\mu_d(\\{\\lambda_i^\\pi\\})\\},\\{\\lambda_i^K\\})\\},\\{\\lambda_i^c\\})\\}) }{\\mathcal{L}(\\{k_d\\}|\\{\\mu_d(\\{\\lambda_i^\\pi=0\\})\\},\\{\\lambda_i^K=0\\})\\},\\{\\lambda_i^c=0\\})\\})} $$\n",
    "\n",
    "the fisher matrix is then given by\n",
    "\n",
    "$$I_{(p,i),(p',j)} = -\\frac{d^2 \\log r}{d \\lambda_i^p d \\lambda_j^{p'}}  \\\\\n",
    "= ... \\\\\n",
    "= \\sum_d \\frac{k_d}{[\\mu_d(\\{\\lambda_i^p\\})]^2} \\frac{d}{d\\lambda_i^p}\\mu_d(\\{\\lambda_i^p\\}) \\frac{d}{d\\lambda_j^{p'}}\\mu_d(\\{\\lambda_j^{p'}\\})\n",
    "$$\n",
    "\n",
    "After some math, we can show\n",
    "\n",
    "$$\\frac{d}{d\\lambda_i^p} \\mu_d(\\{\\lambda_i^p\\}) = G_i^{p,d} - \\frac{1}{N_p} \\sum_{j=0}^{N_p-1} G_j^{p,d}$$\n",
    "\n",
    "so \n",
    "\n",
    "$$I_{(p,i),(p',j)} =\\sum_d \\frac{k_d}{[\\mu_d(\\{\\lambda_i^p\\})]^2}\n",
    "[G_i^{p,d} - \\frac{1}{N_p} \\sum_{k=0}^{N_p-1} G_k^{p,d}]\n",
    "[G_j^{p',d} - \\frac{1}{N_{p'}} \\sum_{k=0}^{N_{p'}-1} G_k^{p',d}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ddbd2-1899-4b44-983d-349ae90bd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {}\n",
    "exposure_factor = 1#yearly_factor\n",
    "for dataset,dname in zip([SINE_rate_nominal, UNDINE_rate_nominal, UNDINE_muons_edist_nominal, UNDINE_electrons_edist_nominal],\n",
    "                         [\"SINE_rate\", \"UNDINE_rate\", \"UNDINE_muons_edist\", \"UNDINE_electrons_edist\"]):\n",
    "    if \"edist\" in dname:\n",
    "        if \"muons\" in dname:\n",
    "            bins = range(len(UNDINE_muon_ebins)-1)\n",
    "        if \"electrons\" in dname:\n",
    "            bins = range(len(UNDINE_electron_ebins)-1)\n",
    "    else:\n",
    "        bins = range(1)\n",
    "    for ibin in bins:\n",
    "        dataset_string = \"%s_bin%d\"%(dname,ibin)\n",
    "        G[dataset_string] = {}\n",
    "        for parent in [\"Pions\",\"Kaons\",\"Charm\"]:\n",
    "            G[dataset_string][parent]= {}\n",
    "            gen_idx = 0 if parent in [\"Pions\",\"Kaons\"] else 1\n",
    "            for generators in zip(light_generators,charm_generators):\n",
    "                if \"edist\" in dname: G[dataset_string][parent][generators[gen_idx]] = dataset[generators][parent][ibin]\n",
    "                else: G[dataset_string][parent][generators[gen_idx]] = dataset[generators][parent]\n",
    "                G[dataset_string][parent][generators[gen_idx]]*=exposure_factor\n",
    "#G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2e009-11b8-4ada-9578-db0dfc315653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "light_generator_base=\"EPOSLHC\"\n",
    "charm_generator_base=\"BKSS\"\n",
    "\n",
    "\n",
    "def f_fs(f_s,parent):\n",
    "    if parent==\"Pions\": \n",
    "        return (1 - f_s)\n",
    "    elif parent==\"Kaons\":\n",
    "        return (1 + 6.6*f_s)\n",
    "    return 1\n",
    "\n",
    "def mu_parent(dataset_name,\n",
    "              parent,\n",
    "              parent_lambdas,\n",
    "              light_generator_base=\"SIBYLL\",\n",
    "              charm_generator_base=\"SIBYLL\"):\n",
    "    Np = len(G[dataset_name][parent].keys())\n",
    "    lambda_bar = np.sum(parent_lambdas)\n",
    "    generators = list(G[dataset_name][parent].keys())\n",
    "    if parent in [\"Pions\",\"Kaons\"]:\n",
    "        generators.remove(light_generator_base)\n",
    "        mu_p = G[dataset_name][parent][light_generator_base] * (1 - lambda_bar)\n",
    "    else:\n",
    "        generators.remove(charm_generator_base)\n",
    "        mu_p = G[dataset_name][parent][charm_generator_base] * (1 - lambda_bar)\n",
    "    for generator,lam in zip(generators,parent_lambdas):\n",
    "        mu_p += G[dataset_name][parent][generator] * (1 + Np*lam - lambda_bar)\n",
    "    mu_p /= Np\n",
    "    return mu_p\n",
    "    \n",
    "def mu(dataset_name,\n",
    "       lambdas,\n",
    "       light_generator_base=\"SIBYLL\",\n",
    "       charm_generator_base=\"SIBYLL\",\n",
    "       f_s = 0):\n",
    "    assert(lambdas.shape==(3,len(G[dataset_name][\"Pions\"])-1))\n",
    "    mu = 0\n",
    "    for ip,parent in enumerate(G[dataset_name].keys()):\n",
    "        if parent==\"All\": continue\n",
    "        mu_p = mu_parent(dataset_name,parent,lambdas[ip],\n",
    "                         light_generator_base=light_generator_base,\n",
    "                         charm_generator_base=charm_generator_base)\n",
    "        mu_p *= f_fs(f_s,parent)\n",
    "        mu += mu_p\n",
    "    return mu\n",
    "\n",
    "def nllh(lambdas,f_s,observation=\"null\"):\n",
    "    lambdas = lambdas.reshape((3,4))\n",
    "    LLH = 0\n",
    "    for dataset_name in G.keys():\n",
    "        mu_d = mu(dataset_name,lambdas=lambdas,f_s=f_s)\n",
    "        if observation==\"null\": k_d = mu(dataset_name,lambdas=np.zeros_like(lambdas),f_s=0)\n",
    "        elif observation==\"alt\": k_d = mu(dataset_name,lambdas=np.zeros_like(lambdas),f_s=f_s)\n",
    "        LLH += k_d*np.log(mu_d) - mu_d - gammaln(k_d)\n",
    "    #print(lambdas,LLH)\n",
    "    return -LLH\n",
    "\n",
    "def delta_llh(lambdas,f_s,observation=\"null\"):\n",
    "    lambdas = lambdas.reshape((3,4))\n",
    "    delta_LLH = 0\n",
    "    #print(lambdas)\n",
    "    for dataset_name in G.keys():\n",
    "        mu_d_null = mu(dataset_name,lambdas=np.zeros_like(lambdas),f_s=0)\n",
    "        mu_d_alt = mu(dataset_name,lambdas=lambdas,f_s=f_s)\n",
    "        if observation==\"null\": k_d = mu_d_null\n",
    "        elif observation==\"alt\": k_d = mu(dataset_name,lambdas=np.zeros_like(lambdas),f_s=f_s)\n",
    "        #print(dataset_name,mu_d_alt,mu_d_null)\n",
    "        delta_LLH += k_d * np.log(mu_d_alt/mu_d_null) - (mu_d_alt - mu_d_null)\n",
    "    return -2 * delta_LLH\n",
    "\n",
    "def profile_llh(f_s,observation=\"null\"):\n",
    "    \n",
    "    args = (f_s,observation)\n",
    "    cons = ({'type': 'ineq', 'fun': lambda x : 1 - sum(x[0:4])},\n",
    "            {'type': 'ineq', 'fun': lambda x : 1 - sum(x[4:8])},\n",
    "            {'type': 'ineq', 'fun': lambda x : 1 - sum(x[8:])})\n",
    "    for dataset_name in G.keys():\n",
    "        for ip,parent in enumerate(G[dataset_name].keys()):\n",
    "            i_lambda_start = 4*ip\n",
    "            i_lambda_end = 4*(ip+1)\n",
    "            generators = list(G[dataset_name][parent].keys())\n",
    "            if parent in [\"Pions\",\"Kaons\"]:\n",
    "                generators.remove(light_generator_base)\n",
    "                X = G[dataset_name][parent][light_generator_base]\n",
    "            else:\n",
    "                generators.remove(charm_generator_base)\n",
    "                X = G[dataset_name][parent][charm_generator_base]\n",
    "            Y = sum([G[dataset_name][parent][g] for g in generators])\n",
    "            lambda_sum_min = -X/(Y - (X+Y)/len(generators))\n",
    "            #print(dataset_name,parent,f_s,lambda_sum_min)\n",
    "            if not np.isnan(lambda_sum_min):\n",
    "                cons += ({'type': 'ineq', 'fun': lambda x : -sum(x[i_lambda_start:i_lambda_end]) + lambda_sum_min},)\n",
    "            \n",
    "    x0 = np.zeros(3*4)\n",
    "    bounds = ((-1,1) for _ in range(len(x0)))\n",
    "    res = minimize(nllh,x0,args,\n",
    "                   bounds=bounds,\n",
    "                   constraints=cons,\n",
    "                   method=\"SLSQP\",\n",
    "                   options={\"maxiter\":1000})\n",
    "    # while np.all(res.x==np.zeros_like(res.x)):\n",
    "    #     x0 = np.array(2*np.random.rand(12)-1,dtype=float) # between -1 and 1\n",
    "    #     print(x0)\n",
    "    #     res = minimize(nllh,x0,args,\n",
    "    #                    bounds=bounds,\n",
    "    #                    constraints=cons,\n",
    "    #                    #method=\"COBYLA\",\n",
    "    #                    options={\"maxiter\":1000})\n",
    "        \n",
    "    \n",
    "    #print(f_s)\n",
    "    #print(res.fun)\n",
    "    #print(np.all(res.x==np.zeros_like(res.x)))\n",
    "    return res.fun\n",
    "    \n",
    "f_s_range = np.logspace(-4,-2,50)\n",
    "llh_null = -73.0265022681658#-profile_llh(0)\n",
    "llh_range = [-2*(-profile_llh(f_s) + llh_null) for f_s in f_s_range]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070e2d7-597a-497b-81ff-ed1446ae4dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f_s_range,llh_range)\n",
    "plt.semilogx()\n",
    "plt.xlim(1e-4,1e-2)\n",
    "plt.ylim(0,10)\n",
    "for sigma in [1,2,3]:\n",
    "    val = chi2.isf(2*norm.sf(sigma),1)\n",
    "    plt.plot([1e-4,1e-2],[val,val],color=\"black\",ls=\"--\",alpha=0.5)\n",
    "    plt.text(2e-4,val+0.2,r\"$%d\\sigma$\"%sigma,fontsize=14)\n",
    "plt.ylabel(r\"$-2(\\log \\mathcal{L}(f_s) - \\log \\mathcal{L}(f_s=0)$\")\n",
    "plt.xlabel(r\"$f_s$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f10ca6-8caa-4aba-a040-de6d1f9b56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fisher_matrix_element(lambdas,\n",
    "                          f_s=0,\n",
    "                          parent_1=None,generator_1=None,\n",
    "                          parent_2=None,generator_2=None,\n",
    "                          dataset_name_1=None,\n",
    "                          dataset_name_2=None,\n",
    "                          f_s_1=False,\n",
    "                          f_s_2=False):\n",
    "    assert(lambdas.shape==(3,len(G[\"SINE_rate_bin0\"][\"Pions\"])-1))\n",
    "    element = 0\n",
    "    if parent_1 and generator_1 and parent_2 and generator_2:\n",
    "        for dataset_name in G.keys():\n",
    "            k = mu(dataset_name,np.zeros_like(lambdas))\n",
    "            _mu = mu(dataset_name,lambdas)\n",
    "            prefactor = k / (_mu**2)\n",
    "            diff1 = G[dataset_name][parent_1][generator_1] - np.average(list(G[dataset_name][parent_1].values()))\n",
    "            diff2 = G[dataset_name][parent_2][generator_2] - np.average(list(G[dataset_name][parent_2].values()))\n",
    "            element += prefactor*diff1*diff2\n",
    "        return element\n",
    "    elif f_s_1 and parent_2 and generator_2:\n",
    "        for dataset_name in G.keys():\n",
    "            k = mu(dataset_name,np.zeros_like(lambdas))\n",
    "            _mu = mu(dataset_name,lambdas)\n",
    "            diff2 = G[dataset_name][parent_2][generator_2] - np.average(list(G[dataset_name][parent_2].values()))\n",
    "            pion_idx = np.where(list(G[dataset_name].keys())==\"Pions\")\n",
    "            kaon_idx = np.where(list(G[dataset_name].keys())==\"Kaons\")\n",
    "            term_left = k/(_mu**2) * f_fs(f_s,parent_2)*(6.6*mu_parent(dataset_name,\"Kaons\",lambdas[kaon_idx]) - mu_parent(dataset_name,\"Pions\",lambdas[pion_idx]))\n",
    "            term_right = (k/_mu - 1) * (6.6*(parent_2==\"Kaons\") - (parent_2==\"Pions\"))\n",
    "            element += diff2 * (term_left - term_right)\n",
    "        return element\n",
    "    elif f_s_2 and parent_1 and generator_1:\n",
    "        for dataset_name in G.keys():\n",
    "            k = mu(dataset_name,np.zeros_like(lambdas))\n",
    "            _mu = mu(dataset_name,lambdas)\n",
    "            diff1 = G[dataset_name][parent_1][generator_1] - np.average(list(G[dataset_name][parent_1].values()))\n",
    "            pion_idx = np.where(list(G[dataset_name].keys())==\"Pions\")\n",
    "            kaon_idx = np.where(list(G[dataset_name].keys())==\"Kaons\")\n",
    "            term_left = k/(_mu**2) * f_fs(f_s,parent_1)*(6.6*mu_parent(dataset_name,\"Kaons\",lambdas[kaon_idx]) - mu_parent(dataset_name,\"Pions\",lambdas[pion_idx]))\n",
    "            term_right = (k/_mu - 1) * (6.6*(parent_1==\"Kaons\") - (parent_1==\"Pions\"))\n",
    "            element += diff1 * (term_left - term_right)\n",
    "        return element\n",
    "    elif f_s_1 and f_s_2:\n",
    "        for dataset_name in G.keys():\n",
    "            k = mu(dataset_name,np.zeros_like(lambdas))\n",
    "            prefactor = k / (mu(dataset_name,lambdas)**2)\n",
    "            pion_idx = np.where(list(G[dataset_name].keys())==\"Pions\")\n",
    "            kaon_idx = np.where(list(G[dataset_name].keys())==\"Kaons\")\n",
    "            element += prefactor * (6.6*mu_parent(dataset_name,\"Kaons\",lambdas[kaon_idx]) - mu_parent(dataset_name,\"Pions\",lambdas[pion_idx]))**2\n",
    "        return element\n",
    "    elif parent_1 and generator_1 and dataset_name_2:\n",
    "        k = mu(dataset_name_2,np.zeros_like(lambdas))\n",
    "        prefactor = k / (mu(dataset_name_2,lambdas)**2)\n",
    "        diff1 = G[dataset_name_2][parent_1][generator_1] - np.average(list(G[dataset_name_2][parent_1].values()))\n",
    "        return prefactor*diff1\n",
    "    elif parent_2 and generator_2 and dataset_name_1:\n",
    "        k = mu(dataset_name_1,np.zeros_like(lambdas))\n",
    "        prefactor = k / (mu(dataset_name_1,lambdas)**2)\n",
    "        diff2 = G[dataset_name_1][parent_2][generator_2] - np.average(list(G[dataset_name_1][parent_2].values()))\n",
    "        return prefactor*diff2\n",
    "    elif dataset_name_1 and dataset_name_2:\n",
    "        k = mu(dataset_name_1,np.zeros_like(lambdas))\n",
    "        prefactor = k / (mu(dataset_name_1,lambdas)**2)\n",
    "        return prefactor*(dataset_name_1==dataset_name_2)\n",
    "    else:\n",
    "        print(\"Invalide fisher matrix element request\")\n",
    "        return -np.inf\n",
    "\n",
    "def condition_number_thresholding(I, threshold=1e-5):\n",
    "    # Step 1: Eigenvalue Decomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(I)\n",
    "\n",
    "    # Step 2: Adjust Small Eigenvalues\n",
    "    # For each eigenvalue, if it's smaller than threshold, set it to threshold\n",
    "    regularized_eigenvalues = np.maximum(eigenvalues, threshold)\n",
    "\n",
    "    # Step 3: Reconstruct the Regularized Matrix\n",
    "    # Rebuild the Fisher matrix using the regularized eigenvalues\n",
    "    regularized_I = (eigenvectors @ np.diag(regularized_eigenvalues) @ eigenvectors.T)\n",
    "\n",
    "    return regularized_I\n",
    "\n",
    "def pca_fisher_reduction(I, variance_threshold=0.999999):\n",
    "    # Step 1: Eigenvalue Decomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(I)\n",
    "\n",
    "    # Step 2: Sort eigenvalues and eigenvectors in descending order of eigenvalue magnitude\n",
    "    indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalues = eigenvalues[indices]\n",
    "    sorted_eigenvectors = eigenvectors[:, indices]\n",
    "\n",
    "    # Step 3: Determine number of components to satisfy variance threshold\n",
    "    total_variance = np.sum(sorted_eigenvalues)\n",
    "    variance_explained = np.cumsum(sorted_eigenvalues) / total_variance\n",
    "    num_components = np.searchsorted(variance_explained, variance_threshold) + 1\n",
    "\n",
    "    # Step 4: Reconstruct Reduced Fisher Matrix\n",
    "    V_selected = sorted_eigenvectors[:, :num_components]\n",
    "    Lambda_selected = np.diag(sorted_eigenvalues[:num_components])\n",
    "    \n",
    "    I_reduced = V_selected @ Lambda_selected @ V_selected.T\n",
    "\n",
    "    return I_reduced\n",
    "\n",
    "def profile_information_matrix(I, param_index):\n",
    "    \"\"\"\n",
    "    Profiles over a single parameter in the Fisher information matrix.\n",
    "\n",
    "    Args:\n",
    "    - I: 2D NumPy array representing the Fisher information matrix.\n",
    "    - param_index: int representing the index of the parameter to profile out.\n",
    "\n",
    "    Returns:\n",
    "    - I_profiled: 2D NumPy array representing the profiled information matrix.\n",
    "    \"\"\"\n",
    "    # Remove the nth row and column to form the reduced information matrix\n",
    "    I_reduced = np.delete(np.delete(I, param_index, axis=0), param_index, axis=1)\n",
    "    \n",
    "    # Extract the nth column, with the nth entry removed, to form the vector m\n",
    "    m = np.delete(I[:, param_index], param_index)\n",
    "\n",
    "    # The diagonal term for normalization\n",
    "    I_nn = I[param_index, param_index]\n",
    "    \n",
    "    # Compute the outer product of m with itself, and normalize by I_nn\n",
    "    m_outer = np.outer(m, m) / I_nn if I_nn != 0 else np.zeros_like(I_reduced)\n",
    "\n",
    "    # Profiled information matrix\n",
    "    I_profiled = I_reduced - m_outer\n",
    "\n",
    "    return I_profiled\n",
    "        \n",
    "    \n",
    "\n",
    "# Construct fisher matrix\n",
    "I_len = len(G[\"SINE_rate_bin0\"])*(len(G[\"SINE_rate_bin0\"][\"Pions\"])-1)\n",
    "I_len += 1 # if using f_s\n",
    "# I_len += len(G) # if using dataset predictions in fisher matrix\n",
    "I = np.zeros((I_len,I_len))\n",
    "print(I.shape)\n",
    "axis_labels = []\n",
    "\n",
    "for ip,(parent_1,parent_label) in enumerate(zip([\"Pions\",\"Kaons\",\"Charm\"],\n",
    "                                                [\"\\pi\",\"K\",\"c\"])):\n",
    "    generators_1 = list(G[\"SINE_rate_bin0\"][parent_1].keys())\n",
    "    if parent_1 in [\"Pions\",\"Kaons\"]: generators_1.remove(light_generator_base)\n",
    "    else: generators_1.remove(charm_generator_base)\n",
    "    for ig,generator_1 in enumerate(generators_1):\n",
    "        i = ip*len(generators_1) + ig\n",
    "        axis_labels.append(r\"$\\lambda^%s_%d$\"%(parent_label,ig+1))\n",
    "        for jp,parent_2 in enumerate([\"Pions\",\"Kaons\",\"Charm\"]):\n",
    "            generators_2 = list(G[\"SINE_rate_bin0\"][parent_2].keys())\n",
    "            if parent_2 in [\"Pions\",\"Kaons\"]: generators_2.remove(light_generator_base)\n",
    "            else: generators_2.remove(charm_generator_base)\n",
    "            for jg,generator_2 in enumerate(generators_2):\n",
    "                j = jp*len(generators_2) + jg\n",
    "                I[i,j] = fisher_matrix_element(lambdas=np.zeros((3,4)),\n",
    "                                               parent_1=parent_1,\n",
    "                                               generator_1=generator_1,\n",
    "                                               parent_2=parent_2,\n",
    "                                               generator_2=generator_2,\n",
    "                                               )\n",
    "                #print(i,j,parent_1,generator_1,parent_2,generator_2,I[i,j])\n",
    "\n",
    "# f_s entries\n",
    "i = len(G[\"SINE_rate_bin0\"])*(len(G[\"SINE_rate_bin0\"][\"Pions\"])-1)\n",
    "axis_labels.append(r\"$f_s$\")\n",
    "for jp,parent_2 in enumerate([\"Pions\",\"Kaons\",\"Charm\"]):\n",
    "    generators_2 = list(G[\"SINE_rate_bin0\"][parent_2].keys())\n",
    "    if parent_2 in [\"Pions\",\"Kaons\"]: generators_2.remove(light_generator_base)\n",
    "    else: generators_2.remove(charm_generator_base)\n",
    "    for jg,generator_2 in enumerate(generators_2):\n",
    "        j = jp*len(generators_2) + jg\n",
    "        I[i,j] = fisher_matrix_element(lambdas=np.zeros((3,4)),\n",
    "                                       f_s_1 = True,\n",
    "                                       parent_2=parent_2,\n",
    "                                       generator_2=generator_2,\n",
    "                                       )\n",
    "        I[j,i] = I[i,j]\n",
    "I[i,i] = fisher_matrix_element(lambdas=np.zeros((3,4)),\n",
    "                               f_s_1 = True,\n",
    "                               f_s_2 = True\n",
    "                               )\n",
    "                \n",
    "# dataset entries\n",
    "def get_number_after_bin(input_string):\n",
    "    # Find the starting index of the substring \"bin\"\n",
    "    bin_index = input_string.find(\"bin\")\n",
    "    \n",
    "    if bin_index != -1:\n",
    "        # The number starts right after the substring \"bin\"\n",
    "        number_start_index = bin_index + len(\"bin\")\n",
    "        \n",
    "        # Extract the substring from the number start index to the end of the string\n",
    "        number_substring = input_string[number_start_index:]\n",
    "        \n",
    "        # Return the number as an integer\n",
    "        return int(number_substring)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def dataset_label(dataset_name):\n",
    "    if \"SINE\" in dataset_name:\n",
    "        #axis_label = r\"\\mu^{\\rm S\\,tot}\"\n",
    "        axis_label = r\"S^{tot}\"\n",
    "    else:\n",
    "        if \"muons\" in dataset_name:\n",
    "            #axis_label = r\"\\mu^{\\rm U\\,\\mu}\"\n",
    "            axis_label = r\"U^{\\mu}\"\n",
    "        elif \"electrons\" in dataset_name:\n",
    "            #axis_label = r\"\\mu^{\\rm U\\,e}\"\n",
    "            axis_label = r\"U^{e}\"\n",
    "        else:\n",
    "            #axis_label = r\"\\mu^{\\rm U\\,tot}\"\n",
    "            axis_label = r\"U^{tot}\"\n",
    "    if \"edist\" in dataset_name:\n",
    "        axis_label += \"_{%d}\"%get_number_after_bin(dataset_name)\n",
    "    return r\"${\\rm %s}$\"%axis_label\n",
    "    \n",
    "# for i_d,dataset_name_1 in enumerate(G.keys()):\n",
    "#     i = len(G[\"SINE_rate_bin0\"])*(len(G[\"SINE_rate_bin0\"][\"Pions\"])-1) + i_d\n",
    "#     axis_labels.append(dataset_label(dataset_name))\n",
    "#     for jp,parent_2 in enumerate([\"Pions\",\"Kaons\",\"Charm\"]):\n",
    "#         generators_2 = list(G[\"SINE_rate_bin0\"][parent_2].keys())\n",
    "#         if parent_2 in [\"Pions\",\"Kaons\"]: generators_2.remove(light_generator_base)\n",
    "#         else: generators_2.remove(charm_generator_base)\n",
    "#         for jg,generator_2 in enumerate(generators_2):\n",
    "#             j = jp*len(generators_2) + jg\n",
    "#             I[i,j] = fisher_matrix_element(lambdas=np.zeros((3,4)),\n",
    "#                                            dataset_name_1=dataset_name_1,\n",
    "#                                            parent_2=parent_2,\n",
    "#                                            generator_2=generator_2,\n",
    "#                                            )\n",
    "#             I[j,i] = I[i,j]\n",
    "            \n",
    "# for i_d,dataset_name_1 in enumerate(G.keys()):\n",
    "#     i = len(G[\"SINE_rate_bin0\"])*(len(G[\"SINE_rate_bin0\"][\"Pions\"])-1) + i_d\n",
    "#     for j_d,dataset_name_2 in enumerate(G.keys()):\n",
    "#         j = len(G[\"SINE_rate_bin0\"])*(len(G[\"SINE_rate_bin0\"][\"Pions\"])-1) + j_d\n",
    "#         I[i,j] = fisher_matrix_element(lambdas=np.zeros((3,4)),\n",
    "#                                        dataset_name_1=dataset_name_1,\n",
    "#                                        dataset_name_2=dataset_name_2,\n",
    "#                                        )\n",
    "\n",
    "I_lambdas = I[:12,:12]\n",
    "axis_labels_lambdas = axis_labels[:12]\n",
    "plt.figure()\n",
    "plt.imshow(I,cmap=\"RdBu\",norm=SymLogNorm(linthresh=1,vmin=-1e6,vmax=1e6))\n",
    "c = plt.colorbar()\n",
    "c.set_label(r\"$\\frac{-d^2 \\log r}{d \\lambda_{i_1}^{p_1} d \\lambda_{i_2}^{p_2}}$\",fontsize=20)\n",
    "# Set the number of ticks to match the length of axis_labels\n",
    "plt.xticks(ticks=range(len(axis_labels)), labels=axis_labels, rotation=90)\n",
    "plt.yticks(ticks=range(len(axis_labels)), labels=axis_labels)\n",
    "plt.savefig(\"Figures/SIREN/FisherMatrix.pdf\",dpi=100)\n",
    "plt.show()\n",
    "\n",
    "I_red = profile_information_matrix(I,0)\n",
    "axis_labels_red = axis_labels.copy()\n",
    "del axis_labels_red[0]\n",
    "while(len(I_red)>1):\n",
    "    I_red = profile_information_matrix(I_red,0)\n",
    "    del axis_labels_red[0]\n",
    "print(I_red**-0.5)\n",
    "plt.imshow(I_red,cmap=\"RdBu\",norm=SymLogNorm(linthresh=1e-1))\n",
    "plt.colorbar()\n",
    "# Set the number of ticks to match the length of axis_labels\n",
    "plt.xticks(ticks=range(len(axis_labels_red)), labels=axis_labels_red, rotation=90)\n",
    "plt.yticks(ticks=range(len(axis_labels_red)), labels=axis_labels_red)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c77d5-52be-4cbf-ad03-c6a2a45d809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.cond(I_lambdas))\n",
    "C = np.linalg.inv(I_lambdas)\n",
    "eigvals,eigvecs = np.linalg.eigh(C)\n",
    "mu_baselines = {dataset_name:mu(dataset_name,np.zeros((3,4))) for dataset_name in G.keys()}\n",
    "mu_baselines_fs = {f_s:{dataset_name:mu(dataset_name,np.zeros((3,4)),f_s=f_s) for dataset_name in G.keys()} for f_s in [0.5,5e-3]}\n",
    "mu_variances = {dataset_name:0 for dataset_name in G.keys()}\n",
    "for eigval,eigvec in zip(eigvals,eigvecs):\n",
    "    # print(eigval)\n",
    "    # print(eigvec)\n",
    "    values = eigval*eigvec\n",
    "    lambdas = values.reshape(3,4)#.T\n",
    "    for dataset_name in G.keys():\n",
    "        diff = mu(dataset_name,lambdas) - mu_baselines[dataset_name]\n",
    "        mu_variances[dataset_name] += diff**2\n",
    "\n",
    "plt.imshow(C,cmap=\"RdBu\",norm=SymLogNorm(linthresh=0.001,vmin=-2e-2,vmax=2e-2))\n",
    "c = plt.colorbar()\n",
    "c.set_label(\"Covariance\")\n",
    "# Set the number of ticks to match the length of axis_labels\n",
    "plt.xticks(ticks=range(len(axis_labels_lambdas)), labels=axis_labels_lambdas, rotation=90)\n",
    "plt.yticks(ticks=range(len(axis_labels_lambdas)), labels=axis_labels_lambdas)\n",
    "plt.savefig(\"Figures/SIREN/CovarianceMatrix.pdf\",dpi=100)\n",
    "plt.show()\n",
    "\n",
    "fig,ax = plt.subplots(2,1,sharex=True,gridspec_kw={'height_ratios': [1.5, 1]})\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "y1 = np.array(list(mu_baselines.values()))\n",
    "y1 = np.array([y1[0]] + list(y1) + [y1[-1]])\n",
    "ymin1,ymax1 = 0.1*np.min(y1),6*np.max(y1)\n",
    "ax[0].step(range(-1,len(mu_baselines)+1),y1,where=\"mid\",color=\"black\",label=r\"$f_s=0$\")\n",
    "y1_fs = np.array(list(mu_baselines_fs[0.5].values()))\n",
    "y1_fs = np.array([y1_fs[0]] + list(y1_fs) + [y1_fs[-1]])\n",
    "ax[0].step(range(-1,len(mu_baselines)+1),y1_fs,where=\"mid\",color=\"red\",label=r\"$f_s=0.5$\")\n",
    "y2 = np.sqrt(list(mu_variances.values()))\n",
    "y2 = np.array([y2[0]] + list(y2) + [y2[-1]])\n",
    "ymin2,ymax2 = 0.99*np.min(1 - y2/y1),1.01*np.max(1 + y2/y1)\n",
    "ax[0].fill_between(range(-1,len(mu_baselines)+1),y1-y2,y1+y2,color=\"black\",alpha=0.5,step=\"mid\")\n",
    "y2_fs = np.array(list(mu_baselines_fs[5e-3].values()))\n",
    "y2_fs = np.array([y2_fs[0]] + list(y2_fs) + [y2_fs[-1]])\n",
    "ymin2 = 0.9#min(0.99*np.min(y2_fs/y1),ymin2)\n",
    "ymax2 = 1.1#max(1.01*np.max(y2_fs/y1),ymax2)\n",
    "ax[1].step(range(-1,len(mu_baselines)+1),y2_fs/y1,where=\"mid\",color=\"blue\",label=r\"$f_s=%1.3f$\"%5e-3)\n",
    "ax[1].fill_between(range(-1,len(mu_variances)+1),1 - y2/y1,1 + y2/y1,color=\"black\",alpha=0.3,step=\"mid\",label=\"Cramer-Rao unc\")\n",
    "tot_err = np.sqrt(y1 + (y2)**2)/y1\n",
    "print(\"y1\",(1/np.sqrt(y1)))\n",
    "print(\"y2\",y2)\n",
    "print(\"tot_err\",tot_err)\n",
    "ax[1].fill_between(range(-1,len(mu_variances)+1),1-tot_err,1 + tot_err,color=\"grey\",alpha=0.3,step=\"mid\",label=r\"$\\sigma_{\\rm CR} \\oplus \\sigma_{\\rm stat}$\")\n",
    "# Set the number of ticks to match the length of axis_labels\n",
    "x_labels = [dataset_label(name) for name in mu_baselines.keys()]\n",
    "ax[1].set_xticks(ticks=range(len(x_labels)), labels=x_labels, rotation=90,fontsize=12)\n",
    "ax[0].set_xlim(-0.5,len(mu_baselines)-0.5)\n",
    "ax[0].set_ylim(ymin1,ymax1)\n",
    "ax[1].set_ylim(ymin2,ymax2)\n",
    "ax[0].set_ylabel(r\"Interactions in $3000~{\\rm fb}^{-1}$\",fontsize=14)\n",
    "ax[1].set_ylabel(r\"Ratio to $f_s=0$\",fontsize=14)\n",
    "ax[0].semilogy()\n",
    "#ax[1].semilogy()\n",
    "ax[0].legend(frameon=False)\n",
    "ax[1].legend(loc=(0.37,-0.05))\n",
    "# dataset divisions\n",
    "for iax,(ymin,ymax) in zip(range(2),[(ymin1,ymax1),(ymin2,ymax2)]):\n",
    "    for i,name in zip([1,2,2+len(UNDINE_muon_ebins)-1,2+len(UNDINE_electron_ebins)+len(UNDINE_muon_ebins)-2],\n",
    "                      [\"SINE Total\",\"UNDINE Total\",r\"UNDINE $\\mu$\",r\"UNDINE $e$\"]):\n",
    "        ax[iax].plot([i-0.5,i-0.5],[ymin,ymax],color=\"black\",lw=1,alpha=0.5)\n",
    "        if iax==0:\n",
    "            if name==r\"UNDINE $\\mu$\":\n",
    "                ax[iax].text(i-len(UNDINE_muon_ebins)/2-1,2*ymin1,name,fontsize=14)\n",
    "                # ax[iax].text(2,2*ymin1,r\"$10^%d$ GeV\"%np.log10(UNDINE_electron_ebins[0]),fontsize=14)\n",
    "                # ax[iax].text(11,2*ymin1,r\"$10^%d$ GeV\"%np.log10(UNDINE_electron_ebins[-1]),fontsize=14)\n",
    "            elif name==r\"UNDINE $e$\":\n",
    "                ax[iax].text(i-len(UNDINE_electron_ebins)/2-1,2*ymin1,name,fontsize=14)\n",
    "            else:\n",
    "                ax[iax].text(i-1.3,2*ymin1,name,rotation=90,fontsize=14)\n",
    "        \n",
    "\n",
    "plt.savefig(\"Figures/SIREN/StrangenessVariations.pdf\",dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d0727-33b7-4a75-b279-13ca26c99f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gammaln\n",
    "\n",
    "def rate_likelihood(SINE_Total_k,UNDINE_Total_k,UNDINE_muons_k,UNDINE_electrons_k,\n",
    "                    SINE_Total_mu,UNDINE_Total_mu,UNDINE_muons_mu,UNDINE_electrons_mu,\n",
    "                    mu_dim=2):\n",
    "    N_mu = SINE_Total_mu.shape[-1]\n",
    "    #print(\"SINE_Total_k\",SINE_Total_k.shape)\n",
    "    #       \"\\nUNDINE_Total_k\",UNDINE_Total_k,\n",
    "    #       \"\\nUNDINE_muons_k\",UNDINE_muons_k,\n",
    "    #       \"\\nUNDINE_electrons_k\",UNDINE_electrons_k)\n",
    "    #print(\"SINE_Total_mu\",SINE_Total_mu.shape)\n",
    "    #       \"\\nUNDINE_Total_mu\",UNDINE_Total_mu,\n",
    "    #       \"\\nUNDINE_muons_mu\",UNDINE_muons_mu,\n",
    "    #       \"\\nUNDINE_electrons_mu\",UNDINE_electrons_mu)\n",
    "    # print(poisson.pmf(SINE_Total_k,SINE_Total_mu))\n",
    "    # print(poisson.pmf(UNDINE_Total_k,UNDINE_Total_mu))\n",
    "    # print(poisson.pmf(UNDINE_muons_k,UNDINE_muons_k))\n",
    "    # print(poisson.pmf(UNDINE_electrons_k,UNDINE_electrons_mu))\n",
    "    logL = np.log(1./N_mu) * np.ones_like(SINE_Total_k)\n",
    "    for k,mu in zip([SINE_Total_k,UNDINE_Total_k,UNDINE_muons_k,UNDINE_electrons_k],\n",
    "                    [SINE_Total_mu,UNDINE_Total_mu,UNDINE_muons_mu,UNDINE_electrons_mu]):\n",
    "        logL_arr = np.einsum('...j,...k->...jk',k,mu)\n",
    "        logL_arr -= np.expand_dims(mu,axis=1)\n",
    "        logL_arr -= np.expand_dims(gammaln(k),axis=2)\n",
    "        m = np.max(logL_arr,axis=mu_dim)\n",
    "        logL += (m + np.log(np.sum(np.exp(logL_arr-np.expand_dims(m,mu_dim)),axis=mu_dim)))\n",
    "    return logL\n",
    "    # return poisson.pmf(SINE_Total_k,SINE_Total_mu) * poisson.pmf(UNDINE_Total_k,UNDINE_Total_mu)  * \\\n",
    "    #        poisson.pmf(UNDINE_muons_k,UNDINE_muons_mu) * poisson.pmf(UNDINE_electrons_k,UNDINE_electrons_mu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50686b53-96a7-4fd5-928e-53edaec3a2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_fs = 100\n",
    "fs_range = np.logspace(-4,0,n_fs)\n",
    "nsigma=1\n",
    "low_cl = (2*(1-norm.cdf(nsigma)))\n",
    "high_cl = 1 - low_cl\n",
    "exposure_factor = 1./1500 # roughly one month\n",
    "n_mu_samples = 1\n",
    "n_k_samples = 10000\n",
    "mu_mean_mode = True\n",
    "\n",
    "fig,ax = plt.subplots(2,1,sharex=True,figsize=(12,8))\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "for lg,cg in zip(light_generators,charm_generators):\n",
    "    print(lg,cg)\n",
    "    c = colors[(lg,cg)]\n",
    "    SINE_Total = {}\n",
    "    UNDINE_Total = {}\n",
    "    UNDINE_muons = {}\n",
    "    UNDINE_electrons = {}\n",
    "    mu_random_idxs = np.random.choice(range(len(np.load(\"%s/SINE_Total_%s_%s_%s.npy\"%(pseudoexp_dir,\"All\",lg,cg)))),size=n_mu_samples)\n",
    "    for k in [\"All\",\"Pions\",\"Kaons\"]:\n",
    "        SINE_Total[k] = exposure_factor*np.load(\"%s/SINE_Total_%s_%s_%s.npy\"%(pseudoexp_dir,k,lg,cg))\n",
    "        UNDINE_Total[k] = exposure_factor*num_UNDINE*np.load(\"%s/UNDINE_Total_%s_%s_%s.npy\"%(pseudoexp_dir,k,lg,cg))\n",
    "        UNDINE_muons[k] = exposure_factor*num_UNDINE*np.load(\"%s/UNDINE_muons_%s_%s_%s.npy\"%(pseudoexp_dir,k,lg,cg))\n",
    "        UNDINE_electrons[k] = exposure_factor*num_UNDINE*np.load(\"%s/UNDINE_electrons_%s_%s_%s.npy\"%(pseudoexp_dir,k,lg,cg))\n",
    "        if mu_mean_mode:\n",
    "            SINE_Total[k] = np.array([np.mean(SINE_Total[k])])\n",
    "            UNDINE_Total[k] = np.array([np.mean(UNDINE_Total[k])])\n",
    "            UNDINE_muons[k] = np.array([np.mean(UNDINE_muons[k])])\n",
    "            UNDINE_electrons[k] = np.array([np.mean(UNDINE_electrons[k])])\n",
    "        else:\n",
    "            SINE_Total[k] = SINE_Total[k][mu_random_idxs]\n",
    "            UNDINE_Total[k] = UNDINE_Total[k][mu_random_idxs]\n",
    "            UNDINE_muons[k] = UNDINE_muons[k][mu_random_idxs]\n",
    "            UNDINE_electrons[k] = UNDINE_electrons[k][mu_random_idxs]\n",
    "            \n",
    "    \n",
    "    SINE_Total_diff = np.outer(6.6*fs_range,SINE_Total[\"Kaons\"]) - np.outer(fs_range,SINE_Total[\"Pions\"])\n",
    "    SINE_Total_mu_null = SINE_Total[\"All\"]\n",
    "    SINE_Total_mu_alt = (np.expand_dims(SINE_Total[\"All\"],0) + SINE_Total_diff)\n",
    "    SINE_Total_k_alt = np.random.poisson(lam=np.expand_dims(SINE_Total_mu_alt,-1),size=(n_fs,n_mu_samples,n_k_samples)).reshape(n_fs,n_mu_samples*n_k_samples)\n",
    "    SINE_Total_k_null = np.random.poisson(lam=np.expand_dims(SINE_Total_mu_null,-1),size=(n_mu_samples,n_k_samples)).reshape(n_mu_samples*n_k_samples)\n",
    "    \n",
    "    UNDINE_Total_diff = np.outer(6.6*fs_range,UNDINE_Total[\"Kaons\"]) - np.outer(fs_range,UNDINE_Total[\"Pions\"])\n",
    "    UNDINE_Total_mu_null = UNDINE_Total[\"All\"]\n",
    "    UNDINE_Total_mu_alt = (np.expand_dims(UNDINE_Total[\"All\"],0) + UNDINE_Total_diff)\n",
    "    UNDINE_Total_k_alt = np.random.poisson(lam=np.expand_dims(UNDINE_Total_mu_alt,-1),size=(n_fs,n_mu_samples,n_k_samples)).reshape(n_fs,n_mu_samples*n_k_samples)\n",
    "    UNDINE_Total_k_null = np.random.poisson(lam=np.expand_dims(UNDINE_Total_mu_null,-1),size=(n_mu_samples,n_k_samples)).reshape(n_mu_samples*n_k_samples)\n",
    "    \n",
    "    UNDINE_muons_diff = np.outer(6.6*fs_range,UNDINE_muons[\"Kaons\"]) - np.outer(fs_range,UNDINE_muons[\"Pions\"])\n",
    "    UNDINE_muons_mu_null = UNDINE_muons[\"All\"]\n",
    "    UNDINE_muons_mu_alt = (np.expand_dims(UNDINE_muons[\"All\"],0) + UNDINE_muons_diff)\n",
    "    UNDINE_muons_k_alt = np.random.poisson(lam=np.expand_dims(UNDINE_muons_mu_alt,-1),size=(n_fs,n_mu_samples,n_k_samples)).reshape(n_fs,n_mu_samples*n_k_samples)\n",
    "    UNDINE_muons_k_null = np.random.poisson(lam=np.expand_dims(UNDINE_muons_mu_null,-1),size=(n_mu_samples,n_k_samples)).reshape(n_mu_samples*n_k_samples)\n",
    "    \n",
    "    UNDINE_electrons_diff = np.outer(6.6*fs_range,UNDINE_electrons[\"Kaons\"]) - np.outer(fs_range,UNDINE_electrons[\"Pions\"])\n",
    "    UNDINE_electrons_mu_null = UNDINE_electrons[\"All\"]\n",
    "    UNDINE_electrons_mu_alt = (np.expand_dims(UNDINE_electrons[\"All\"],0) + UNDINE_electrons_diff)\n",
    "    UNDINE_electrons_k_alt = np.random.poisson(lam=np.expand_dims(UNDINE_electrons_mu_alt,-1),size=(n_fs,n_mu_samples,n_k_samples)).reshape(n_fs,n_mu_samples*n_k_samples)\n",
    "    UNDINE_electrons_k_null = np.random.poisson(lam=np.expand_dims(UNDINE_electrons_mu_null,-1),size=(n_mu_samples,n_k_samples)).reshape(n_mu_samples*n_k_samples)\n",
    "    \n",
    "    # print(\"k_alt\",np.mean(SINE_Total_k_alt,axis=-1))\n",
    "    # print(\"k_null\",np.mean(SINE_Total_k_null))\n",
    "    # print(\"mu_alt\",np.mean(SINE_Total_mu_alt,axis=-1))\n",
    "    # print(\"mu_null\",np.median(SINE_Total_mu_null),np.sqrt(np.median(SINE_Total_mu_null)))\n",
    "    \n",
    "#     SINE_Total_mu_null = exposure_factor*SINE_rate_nominal[(lg,cg)][\"All\"]\n",
    "#     UNDINE_Total_mu_null = exposure_factor*UNDINE_rate_nominal[(lg,cg)][\"All\"]\n",
    "#     UNDINE_electrons_mu_null = exposure_factor*UNDINE_electrons_nominal[(lg,cg)][\"All\"]\n",
    "#     UNDINE_muons_mu_null = exposure_factor*UNDINE_muons_nominal[(lg,cg)][\"All\"]\n",
    "    \n",
    "#     SINE_Total_mu_alt = exposure_factor*np.expand_dims(SINE_rate_nominal[(lg,cg)][\"All\"],0) + np.outer(6.6*fs_range,SINE_rate_nominal[(lg,cg)][\"Pions\"]) - np.outer(fs_range,SINE_rate_nominal[(lg,cg)][\"Kaons\"])\n",
    "#     UNDINE_Total_mu_alt = exposure_factor*np.expand_dims(UNDINE_rate_nominal[(lg,cg)][\"All\"],0) + np.outer(6.6*fs_range,UNDINE_rate_nominal[(lg,cg)][\"Pions\"]) - np.outer(fs_range,UNDINE_rate_nominal[(lg,cg)][\"Kaons\"])\n",
    "#     UNDINE_electrons_mu_alt = exposure_factor*np.expand_dims(UNDINE_electrons_nominal[(lg,cg)][\"All\"],0) + np.outer(6.6*fs_range,UNDINE_electrons_nominal[(lg,cg)][\"Pions\"]) - np.outer(fs_range,UNDINE_electrons_nominal[(lg,cg)][\"Kaons\"])\n",
    "#     UNDINE_muons_mu_alt = exposure_factor*np.expand_dims(UNDINE_muons_nominal[(lg,cg)][\"All\"],0) + np.outer(6.6*fs_range,UNDINE_muons_nominal[(lg,cg)][\"Pions\"]) - np.outer(fs_range,UNDINE_muons_nominal[(lg,cg)][\"Kaons\"])\n",
    "    \n",
    "    likelihood_null_null = rate_likelihood(SINE_Total_k=np.expand_dims(SINE_Total_k_null,0),\n",
    "                                           UNDINE_Total_k=np.expand_dims(UNDINE_Total_k_null,0),\n",
    "                                           UNDINE_muons_k=np.expand_dims(UNDINE_muons_k_null,0),\n",
    "                                           UNDINE_electrons_k=np.expand_dims(UNDINE_electrons_k_null,0),\n",
    "                                           SINE_Total_mu=np.expand_dims(SINE_Total_mu_null,0),\n",
    "                                           UNDINE_Total_mu=np.expand_dims(UNDINE_Total_mu_null,0),\n",
    "                                           UNDINE_muons_mu=np.expand_dims(UNDINE_muons_mu_null,0),\n",
    "                                           UNDINE_electrons_mu=np.expand_dims(UNDINE_electrons_mu_null,0)\n",
    "                                          )\n",
    "    \n",
    "    #print('nn',likelihood_null_null.shape)\n",
    "    \n",
    "    likelihood_null_alt = rate_likelihood(SINE_Total_k=np.repeat(np.expand_dims(SINE_Total_k_null,0),n_fs,axis=0),\n",
    "                                          UNDINE_Total_k=np.repeat(np.expand_dims(UNDINE_Total_k_null,0),n_fs,axis=0),\n",
    "                                          UNDINE_muons_k=np.repeat(np.expand_dims(UNDINE_muons_k_null,0),n_fs,axis=0),\n",
    "                                          UNDINE_electrons_k=np.repeat(np.expand_dims(UNDINE_electrons_k_null,0),n_fs,axis=0),\n",
    "                                          SINE_Total_mu=SINE_Total_mu_alt,\n",
    "                                          UNDINE_Total_mu=UNDINE_Total_mu_alt,\n",
    "                                          UNDINE_muons_mu=UNDINE_muons_mu_alt,\n",
    "                                          UNDINE_electrons_mu=UNDINE_electrons_mu_alt\n",
    "                                         )\n",
    "    \n",
    "    #print('na',likelihood_null_alt.shape)\n",
    "    \n",
    "    likelihood_alt_null = rate_likelihood(SINE_Total_k=SINE_Total_k_alt,\n",
    "                                          UNDINE_Total_k=UNDINE_Total_k_alt,\n",
    "                                          UNDINE_muons_k=UNDINE_muons_k_alt,\n",
    "                                          UNDINE_electrons_k=UNDINE_electrons_k_alt,\n",
    "                                          SINE_Total_mu=np.repeat(np.expand_dims(SINE_Total_mu_null,axis=0),n_fs,axis=0),\n",
    "                                          UNDINE_Total_mu=np.repeat(np.expand_dims(UNDINE_Total_mu_null,axis=0),n_fs,axis=0),\n",
    "                                          UNDINE_muons_mu=np.repeat(np.expand_dims(UNDINE_muons_mu_null,axis=0),n_fs,axis=0),\n",
    "                                          UNDINE_electrons_mu=np.repeat(np.expand_dims(UNDINE_electrons_mu_null,axis=0),n_fs,axis=0)\n",
    "                                         )\n",
    "    \n",
    "    #print('an',likelihood_alt_null.shape)\n",
    "    \n",
    "    likelihood_alt_alt = rate_likelihood(SINE_Total_k=SINE_Total_k_alt,\n",
    "                                         UNDINE_Total_k=UNDINE_Total_k_alt,\n",
    "                                         UNDINE_muons_k=UNDINE_muons_k_alt,\n",
    "                                         UNDINE_electrons_k=UNDINE_electrons_k_alt,\n",
    "                                         SINE_Total_mu=SINE_Total_mu_alt,\n",
    "                                         UNDINE_Total_mu=UNDINE_Total_mu_alt,\n",
    "                                         UNDINE_muons_mu=UNDINE_muons_mu_alt,\n",
    "                                         UNDINE_electrons_mu=UNDINE_electrons_mu_alt\n",
    "                                        )\n",
    "    \n",
    "    #print('aa',likelihood_alt_alt.shape)\n",
    "    \n",
    "    delta_LLH_alt = likelihood_alt_alt - likelihood_alt_null\n",
    "    delta_LLH_null = likelihood_null_alt - likelihood_null_null\n",
    "    significance = (np.median(delta_LLH_alt,axis=-1) - np.median(delta_LLH_null,axis=-1)) / np.std(delta_LLH_null,axis=-1)\n",
    "    \n",
    "#     for ska,sma,utka,utma,umka,umma,ueka,uema,laa,lan,lna,dla,dln,fs in zip(\n",
    "#         SINE_Total_k_alt,SINE_Total_mu_alt,\n",
    "#         UNDINE_Total_k_alt,UNDINE_Total_mu_alt,\n",
    "#         UNDINE_muons_k_alt,UNDINE_muons_mu_alt,\n",
    "#         UNDINE_electrons_k_alt,UNDINE_electrons_mu_alt,\n",
    "#         likelihood_alt_alt,likelihood_alt_null,\n",
    "#         likelihood_null_alt,\n",
    "#         delta_LLH_alt,delta_LLH_null,fs_range):\n",
    "        \n",
    "#         plt.hist(SINE_Total_k_null.flatten(),alpha=0.2,color=\"blue\")\n",
    "#         plt.hist(SINE_Total_mu_null.flatten(),alpha=1,color=\"blue\",histtype=\"step\")\n",
    "#         plt.hist(ska.flatten(),alpha=0.2,color=\"orange\")\n",
    "#         plt.hist(sma.flatten(),alpha=1,color=\"orange\",histtype=\"step\")\n",
    "#         plt.title(fs)\n",
    "#         plt.xlabel(\"SINE_Total\")\n",
    "#         plt.semilogy()\n",
    "#         plt.show()\n",
    "        \n",
    "#         plt.hist(UNDINE_Total_k_null.flatten(),alpha=0.2,color=\"blue\")\n",
    "#         plt.hist(UNDINE_Total_mu_null.flatten(),alpha=1,color=\"blue\",histtype=\"step\")\n",
    "#         plt.hist(utka.flatten(),alpha=0.2,color=\"orange\")\n",
    "#         plt.hist(utma.flatten(),alpha=1,color=\"orange\",histtype=\"step\")\n",
    "#         plt.title(fs)\n",
    "#         plt.xlabel(\"UNDINE_Total\")\n",
    "#         plt.semilogy()\n",
    "#         plt.show()\n",
    "        \n",
    "#         plt.hist(UNDINE_muons_k_null.flatten(),alpha=0.2,color=\"blue\")\n",
    "#         plt.hist(UNDINE_muons_mu_null.flatten(),alpha=1,color=\"blue\",histtype=\"step\")\n",
    "#         plt.hist(umka.flatten(),alpha=0.2,color=\"orange\")\n",
    "#         plt.hist(umma.flatten(),alpha=1,color=\"orange\",histtype=\"step\")\n",
    "#         plt.title(fs)\n",
    "#         plt.xlabel(\"UNDINE_muons\")\n",
    "#         plt.semilogy()\n",
    "#         plt.show()\n",
    "        \n",
    "#         plt.hist(UNDINE_electrons_k_null.flatten(),alpha=0.2,color=\"blue\")\n",
    "#         plt.hist(UNDINE_electrons_mu_null.flatten(),alpha=1,color=\"blue\",histtype=\"step\")\n",
    "#         plt.hist(ueka.flatten(),alpha=0.2,color=\"orange\")\n",
    "#         plt.hist(uema.flatten(),alpha=1,color=\"orange\",histtype=\"step\")\n",
    "#         plt.title(fs)\n",
    "#         plt.xlabel(\"UNDINE_electrons\")\n",
    "#         plt.semilogy()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # plt.hist(laa,histtype=\"step\",label=\"laa\")\n",
    "#         # plt.hist(lan,histtype=\"step\",label=\"lan\")\n",
    "#         # plt.hist(lna,histtype=\"step\",label=\"lna\")\n",
    "#         # plt.hist(likelihood_null_null[0],histtype=\"step\",label=\"lnn\")\n",
    "#         # plt.legend()\n",
    "#         # plt.semilogy()\n",
    "#         # plt.show()\n",
    "#         plt.hist(dla,histtype=\"step\",label=\"dla\")\n",
    "#         plt.hist(dln,histtype=\"step\",label=\"dln\")\n",
    "#         plt.legend()\n",
    "#         plt.semilogy()\n",
    "#         plt.show()\n",
    "    \n",
    "    # discovery_potential = np.count_nonzero(np.less(likelihood_null,np.expand_dims(np.median(likelihood_alt,axis=-1),axis=-1)),axis=-1) / likelihood_null.shape[-1]\n",
    "    # print(discovery_potential)\n",
    "    \n",
    "    #plt.hist(LLH)\n",
    "    \n",
    "    r1 = SINE_Total_mu_alt/SINE_Total_mu_null\n",
    "    r2 = UNDINE_Total_mu_alt/UNDINE_Total_mu_null\n",
    "    r3 = UNDINE_muons_mu_alt/UNDINE_muons_mu_null\n",
    "    r4 = UNDINE_electrons_mu_alt/UNDINE_electrons_mu_null\n",
    "    \n",
    "    #if \"SIBYLL\" in lg:\n",
    "    ax[0].plot(fs_range,np.median(r1,axis=-1),color=c)\n",
    "    ax[0].plot(fs_range,np.median(r2,axis=-1),color=c,ls=\"--\")\n",
    "    ax[0].plot(fs_range,np.median(r3,axis=-1),color=c,ls=\"-.\")\n",
    "    ax[0].plot(fs_range,np.median(r4,axis=-1),color=c,ls=\":\")\n",
    "    ax[1].plot([],[],color=c,label=\"%s + %s\"%(lg,cg))\n",
    "    ax[1].plot(fs_range,significance,color=c)\n",
    "    \n",
    "ax[0].semilogx()\n",
    "ax[1].semilogx()\n",
    "ax[0].set_ylim(0.99,1.2)\n",
    "ax[1].set_ylim(0.01,10)\n",
    "ax[1].set_xlim(fs_range[0],fs_range[-1])\n",
    "ax[1].set_xlabel(r\"$f_s$\")\n",
    "ax[0].set_ylabel(r\"$(f_s^{\\rm true} = f_s)/(f_s^{\\rm true} = 0)$\")\n",
    "ax[1].set_ylabel(r\"Significance ($\\sigma$)\")\n",
    "ax[0].plot([],[],color=\"black\",label=\"SINE Total\")\n",
    "ax[0].plot([],[],color=\"black\",label=\"UNDINE Total\",ls=\"--\")\n",
    "ax[0].plot([],[],color=\"black\",label=\"UNDINE Muons\",ls=\"-.\")\n",
    "ax[0].plot([],[],color=\"black\",label=\"UNDINE Electrons\",ls=\":\")\n",
    "for i in range(2):\n",
    "    ax[i].axvspan(0.3,0.8,color=\"grey\",alpha=0.3)\n",
    "    ax[i].axvspan(0.005,0.3,color=\"grey\",alpha=0.1)\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[1].legend(title=r\"%d ${\\rm fb}^{-1}$ (%2.1f days)\"%(3000*exposure_factor,exposure_factor/yearly_factor*365),loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Figures/SIREN/StrangenessEnhancement.pdf\",dpi=100)\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd6e93-58d0-4c53-96f2-34e1108df288",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66270f3e-ad88-482d-8f02-5304149d6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ak.from_parquet(\"/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/nkamp/Geneva/Lake_Geneva_Neutrinos/Data/SIREN/Output/UNDINE_LHCb_North/LHC13_EPOSLHC_light_-12_CC_TEST.parquet\")\n",
    "#test = ak.from_parquet(\"/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/nkamp/Geneva/Lake_Geneva_Neutrinos/Data/SIREN/Output/UNDINE_CMS_East/LHC13_EPOSLHC_light_12_CC_TEST.parquet\")\n",
    "\n",
    "test.int_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf9ca8-c2f0-450a-b7cb-9473c4b4e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = test.weights*num_UNDINE*np.array(test.in_fiducial)[:,-1]\n",
    "print(sum(weights))\n",
    "print(sum(np.array(test.in_fiducial)[:,-1])/len(test.in_fiducial))\n",
    "print(sum(weights)/(sum(np.array(test.in_fiducial)[:,-1])/len(test.in_fiducial)))\n",
    "plt.hist(test.energy,weights=weights,bins=np.logspace(1,4,30))\n",
    "plt.loglog()\n",
    "plt.ylim(1e0,1e5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeeb671-4725-4f15-8d22-b48cf2cafaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test.int_probs[np.array(test.in_fiducial)[:,-1]],alpha=0.5,bins=np.logspace(-20,10,50))\n",
    "plt.hist(test.int_probs[np.logical_not(np.array(test.in_fiducial)[:,-1])],alpha=0.5,bins=np.logspace(-20,10,50))\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534ec03-e141-42b4-9c9b-1079068f5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "philip_xsdir = \"/n/holylfs05/LABS/arguelles_delgado_lab/Everyone/nkamp/Geneva/Lake_Geneva_Neutrinos/Data/SIREN/CrossSections\"\n",
    "x = pd.read_csv(\"%s/xs_wcg24b_isoscalar.txt\"%philip_xsdir)\n",
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25e181-3f0c-48de-a4db-3e2780bcccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pstr in [\"NUMU\",\"NUTAU\"]:\n",
    "    fig,ax = plt.subplots(2,1,sharex=True)\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    for xs_mode in [\"CC\",\"NC\"]:\n",
    "        for particle,color in zip([\"%s\"%pstr,\"%sBAR\"%pstr],\n",
    "                                  [\"orangered\",\"dodgerblue\"]):\n",
    "            xs = x[\"%s_%s[CM2]\"%(particle,xs_mode)]*1e-36 # pb to cm2\n",
    "            unc = x[\"UNC_%s_%s[%%]\"%(particle,xs_mode)]\n",
    "            ls = \"-\" if xs_mode==\"CC\" else \"--\"\n",
    "            ax[0].plot(x[\"E[GEV]\"],xs,ls=ls,color=color)\n",
    "            #ax[1].plot(x[\"E[GEV]\"],(1-unc/100),color=color,ls=ls)\n",
    "            ax[1].plot(x[\"E[GEV]\"],(unc),color=color,ls=ls,label=\"%s %s\"%(particle,xs_mode))\n",
    "    ax[0].loglog()\n",
    "    ax[1].semilogx()\n",
    "    ax[1].set_xlim(list(x[\"E[GEV]\"])[0],list(x[\"E[GEV]\"])[-1])\n",
    "    ax[1].legend(ncol=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55b494-68ef-46cd-b0ec-d1964ca7d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[('SINE_CMS_West', 'CC', 'LHC13', 'DPMJET', 'light', 14)]\n",
    "data_test[\"panel_hit\"] = np.where(data_test.panel1_hit_mask_muon_survival,1,\n",
    "                               np.where(data_test.panel2_hit_mask_muon_survival,2,\n",
    "                                        np.where(data_test.panel3_hit_mask_muon_survival,3,0)))\n",
    "data_test\n",
    "hit_location = [x[\"panel%d_int_locations\"%x.panel_hit][0] for x in data_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a579a-457c-4998-8146-0d98b08cf5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f4dc56-909f-495d-b24a-beb498f56cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lienv",
   "language": "python",
   "name": "lienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
